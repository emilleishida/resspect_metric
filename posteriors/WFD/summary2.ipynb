{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_names = {90:'Ia', 67: '91bg', 52:'Iax', 42:'II', 62:'Ibc', \n",
    "               95: 'SLSN', 15:'TDE', 64:'KN', 88:'AGN', 92:'RRL', 65:'M-dwarf',\n",
    "               16:'EB',53:'Mira', 6:'MicroL', 991:'MicroLB', 992:'ILOT', \n",
    "               993:'CART', 994:'PISN',995:'MLString'}\n",
    "\n",
    "SNANA_types = {90:11, 62:{1:3, 2:13}, 42:{1:2, 2:12, 3:14},\n",
    "               67:41, 52:43, 64:51, 95:60, 994:61, 992:62,\n",
    "               993:63, 15:64, 88:70, 92:80, 65:81, 16:83,\n",
    "               53:84, 991:90, 6:{1:91, 2:93}}\n",
    "\n",
    "SNANA_names = {11: 'Ia', 3:'Ibc', 13: 'Ibc', 2:'II', 12:'II', 14:'II',\n",
    "               41: '91bg', 43:'Iax', 51:'KN', 60:'SLSN', 61:'PISN', 62:'ILOT',\n",
    "               63:'CART', 64:'TDE', 70:'AGN', 80:'RRL', 81:'M-dwarf', 83:'EB',\n",
    "               84:'Mira', 90:'MicroLB', 91:'MicroL', 93:'MicroL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "cases = os.listdir('/media/emille/git/COIN/RESSPECT_work/PLAsTiCC/' + \\\n",
    "                   'metrics_paper/' + \\\n",
    "                   'resspect_metric/SALT2_fit/WFD' + str(k) + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cases.remove('fiducial.csv')\n",
    "#cases.remove('random.csv')\n",
    "#cases.remove('non-survivors')\n",
    "#cases.remove('fiducial6000fail5999.csv')\n",
    "#cases.remove('perfect6000.csv')\n",
    "cases.remove('.ipynb_checkpoints')\n",
    "#cases.remove('3000_0.csv')\n",
    "#cases.remove('75SNIa25SNIax.csv')\n",
    "if k == '':\n",
    "    cases.remove('perfect1500.csv')\n",
    "    cases.remove('perfect6000.csv')\n",
    "    cases.remove('perfect3000_IX.csv')\n",
    "    cases.remove('perfect3000_I.csv') \n",
    "    cases.remove('perfect3000_II.csv')\n",
    "    cases.remove('perfect3000_III.csv')\n",
    "    cases.remove('perfect3000_IV.csv')\n",
    "    cases.remove('perfect3000_V.csv')\n",
    "    cases.remove('perfect3000_VI.csv')\n",
    "    cases.remove('perfect3000_VII.csv')\n",
    "    cases.remove('perfect3000_VIII.csv')\n",
    "    cases.remove('perfect3000_0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name in cases:\n",
    "    \n",
    "    print(name)\n",
    "\n",
    "    fname = '/media/emille/git/COIN/RESSPECT_work/PLAsTiCC/metrics_paper/' + \\\n",
    "            'resspect_metric/SALT2_fit/WFD' + str(k) + '/' \\\n",
    "              + name \n",
    "\n",
    "    data = pd.read_csv(fname)\n",
    "\n",
    "    types, freq = np.unique(data['SIM_TYPE_INDEX'].values, return_counts=True)\n",
    "        \n",
    "    print('\\n')\n",
    "    print('case: ' + name)\n",
    "    for i in range(len(types)):\n",
    "        print('perc ' + SNANA_names[types[i]] + ' : ', round(freq[i]/data.shape[0], 2))\n",
    "    print('Total number: ', data.shape[0])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read Wassernstein distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/media/emille/git/COIN/RESSPECT_work/PLAsTiCC/metrics_paper/' + \\\n",
    "        'resspect_metric/Wasserstein/wassersteinDistances_wfd' + str(k) +'.dat'\n",
    "\n",
    "wdist = pd.read_csv(fname)\n",
    "name_flagA = np.array(['perfect3000' in name for name in wdist['FileA'].values])\n",
    "name_flagB = np.array(['perfect3000' in name for name in wdist['FileB'].values])\n",
    "name_flag = np.logical_or(name_flagA, name_flagB)\n",
    "\n",
    "wdist_wfd = wdist[name_flag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proclam\n",
    "from proclam.metrics.util import *\n",
    "from proclam.metrics.util import RateMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class det_mets(RateMatrix):\n",
    "    \"binary classification metrics\"\n",
    "    def __init__(self, **rates):\n",
    "        \"\"\"\n",
    "        Call like `thing = det_mets(**rates._asdict())`\n",
    "        \"\"\"\n",
    "#         self.rates = rates#.asdict()\n",
    "        self._get_tots()\n",
    "        self._from_rates()\n",
    "        self._sn_mets()\n",
    "        self._translate()\n",
    "    def _get_tots(self):\n",
    "        self.CP = self.TP + self.FN\n",
    "        self.CN = self.TN + self.FP\n",
    "        self.T = self.TP + self.TN\n",
    "        self.F = self.FP + self.FN\n",
    "        self.P = self.TP + self.FP\n",
    "        self.N = self.TN + self.FN\n",
    "    def _from_rates(self):\n",
    "        self.PPV = self.TP / (self.TP + self.FP)\n",
    "        self.NPV = self.TN / (self.TN + self.FN)\n",
    "        self.PT = (np.sqrt(self.TPR * (1. - self.TNR)) + self.TNR - 1.) / (self.TPR + self.TNR - 1.)\n",
    "        self.TS = self.TP / (self.TP + self.FN + self.FP)\n",
    "        self._derived()\n",
    "    def _derived(self):\n",
    "        self.ACC = (self.TP + self.TN) / (self.CP + self.CN)\n",
    "        self.BA = (self.TPR + self.TNR) / 2,\n",
    "        self.F1S = 2. * self.PPV * self.TPR / (self.PPV + self.TPR)\n",
    "        self.MCC = (self.TP * self.TN - self.FP * self.FN) / (np.sqrt(self.P * self.CP * self.CN * self.N))\n",
    "        self.FM = np.sqrt(self.PPV * self.TPR)\n",
    "        self.BM = self.TPR + self.TNR - 1.\n",
    "        self.MK = self.PPV + self.NPV - 1.\n",
    "    def _translate(self):\n",
    "        self.positive = self.CP\n",
    "        self.negative = self.CN\n",
    "        self.sensitivity = self.TPR\n",
    "        self.recall = self.TPR\n",
    "        self.specificity = self.TNR\n",
    "        self.selectivity = self.TNR\n",
    "        self.precision = self.PPV\n",
    "        self.FDR = 1. - self.PPV\n",
    "        self.FOR = 1. - self.NPV\n",
    "        self.CSI = self.TS\n",
    "        self.accuracy = self.ACC\n",
    "        self.f1_score = self.F1S\n",
    "        self.informedness = self.BM\n",
    "        self.deltaP = self.MK\n",
    "    def _sn_mets(self):\n",
    "        self.get_efficiency()\n",
    "        self.get_purity()\n",
    "    def get_efficiency(self):\n",
    "        self.efficiency = self.TP / self.CP\n",
    "        return self.efficiency\n",
    "    def get_purity(self):\n",
    "        self.purity = self.TP / self.P\n",
    "        return self.purity\n",
    "    def get_fom(self, penalty):\n",
    "        self.pseudo_purity = self.TP / (self.TP + penalty * self.FP)\n",
    "        return self.pseudo_purity * self.efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nums_to_rate(tot, P, T, FP):\n",
    "    N = tot - P\n",
    "    TN = N - FP\n",
    "    F = tot - T\n",
    "    FN = F - TN\n",
    "    TP = P - FN\n",
    "    assert(FP + FN + TP + TN == tot)\n",
    "    \n",
    "    TPR = TP / P\n",
    "    FPR = FP / N\n",
    "    FNR = FN / P\n",
    "    TNR = TN / N\n",
    "    \n",
    "#     cm = np.array([[totIa - cont, totall - ], [, cont]])\n",
    "    rate = proclam.util.RateMatrix(TPR=TPR, FPR=FPR, FNR=FNR, TNR=TNR, TP=TP, FN=FN, TN=TN, FP=FP)\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(cont, totIa=3000, before_salt2=False, field='DDF'):\n",
    "    \"\"\"Classification metrics for a sample of 3k SNIa.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cont: int < totIa\n",
    "        number of contaminant objects\n",
    "    totIa: int (optional)\n",
    "        Number of Ia in the sample. Default is 3000.\n",
    "    before_salt2: bool (optional)\n",
    "        If True use total sample number before SALT2 fit.\n",
    "        Default is False.\n",
    "    field: str (optional)\n",
    "        Cadence: 'DDF' or 'WFD'. Default is DDF.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    accuracy: floatTPR=TPR, FPR=FPR, FNR=FNR, TNR=TNR, TP=TP, FN=FN, TN=TN, FP=FP\n",
    "    efficiency: float\n",
    "    purity: float\n",
    "    figure of merit (W=1): float\n",
    "    figure of merit (W=3): float\n",
    "    \"\"\"\n",
    "    \n",
    "    if totIa != 3000:\n",
    "        raise ValueError('Numbers are hard coded for 3000 SNIa.')\n",
    "    \n",
    "    total = {}\n",
    "    total['DDF'] = {}                     # total number of objects in the sample\n",
    "    total['DDF']['before_salt2'] = 4335\n",
    "    total['DDF']['after_salt2'] = 3456\n",
    "    total['WFD'] = {}\n",
    "    total['WFD']['before_salt2'] = 5588\n",
    "    total['WFD']['after_salt2'] = 3306\n",
    "    \n",
    "    if before_salt2:\n",
    "        totall = total[field]['before_salt2']\n",
    "    else:\n",
    "        totall = total[field]['after_salt2']\n",
    "    \n",
    "    rate = nums_to_rate(tot=totall, P=totIa, T=totIa, FP=cont)._asdict()\n",
    "    class_mets = det_mets(**rate)\n",
    "    \n",
    "#     acc = (totall - (2* totIa * cont))/totall\n",
    "#     eff = (totIa - totIa * cont)/totIa\n",
    "#     f1 = ((totIa - totIa * cont)/totIa) * (1 - cont)\n",
    "#     f3 = ((1 - cont) * totIa)/(((1-cont) * totIa) + 3 * ((cont) * totIa))\n",
    "    \n",
    "#     return acc, eff, 1 - cont, f1, f3\n",
    "    return class_mets.accuracy, class_mets.efficiency, class_mets.purity, class_mets.f1_score, class_mets.get_fom(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "\n",
    "pop_Ia_all = []\n",
    "pop_nIa_all = []\n",
    "perc_Ia_all = []\n",
    "perc_nIa_all = []\n",
    "\n",
    "wfit_w_all = []\n",
    "wfit_wsig_all = []\n",
    "wfit_om_all = []\n",
    "wfit_omsig_all = []\n",
    "\n",
    "wfit_w_all_lowz = []\n",
    "wfit_wsig_all_lowz = []\n",
    "wfit_om_all_lowz = []\n",
    "wfit_omsig_all_lowz = []\n",
    "\n",
    "wdist_median = []\n",
    "\n",
    "stan_w_all = []\n",
    "stan_wsig_all = []\n",
    "stan_om_all = []\n",
    "stan_omsig_all = []\n",
    "\n",
    "stan_w_all_lowz = []\n",
    "stan_wsig_all_lowz = []\n",
    "stan_om_all_lowz = []\n",
    "stan_omsig_all_lowz = []\n",
    "\n",
    "other_index = []\n",
    "other_name = []\n",
    "\n",
    "eff = []\n",
    "pur = []\n",
    "acc = []\n",
    "f1 = []\n",
    "f3 = []\n",
    "\n",
    "for case in cases:\n",
    "    \n",
    "    print(case)\n",
    "\n",
    "    names.append(case[:-4])\n",
    "    \n",
    "    pop = {}\n",
    "    perc = {}\n",
    "\n",
    "    samples_dir = case[:-4] + '/'\n",
    "    \n",
    "    data = pd.read_csv('/media/emille/git/COIN/RESSPECT_work/PLAsTiCC/metrics_paper/' +\\\n",
    "                       'resspect_metric/SALT2_fit/WFD' + str(k) + '/' + case)\n",
    "    stats = np.unique(data['SIM_TYPE_INDEX'].values, return_counts=True)\n",
    "   \n",
    "    fname_cosmo_lowz = '/media/emille/git/COIN/RESSPECT_work/PLAsTiCC/metrics_paper/resspect_metric/' + \\\n",
    "                    'posteriors/WFD/' + case[:-4] + '/' + \\\n",
    "                    'test_mysamples' + str(k) + '/omprior_0.01_flat/results/test_salt2mu_lowz_withbias_' + case[:-4] + '.M0DIF.cospar'\n",
    "    cosmofit_lowz = pd.read_csv(fname_cosmo_lowz, delim_whitespace=True,\n",
    "                          comment='#', names=['w', 'wsig_marg',  'OM',  'OM_sig',  'chi2',  \n",
    "                                              'Ndof',  'sigint', 'wran',  'OMran',  'label'])\n",
    "    wfit_w_all_lowz.append(cosmofit_lowz['w'].values[0])\n",
    "    wfit_wsig_all_lowz.append(cosmofit_lowz['wsig_marg'].values[0])\n",
    "    wfit_om_all_lowz.append(cosmofit_lowz['OM'].values[0])\n",
    "    wfit_omsig_all_lowz.append(cosmofit_lowz['OM_sig'].values[0])\n",
    "\n",
    "    fname_stan = case[:-4] + '/test_mysamples' + str(k) + '/omprior_0.01_flat/results/stan_summary_' + case[:-4] + '_lowz_withbias.dat'\n",
    "    op2 = open(fname_stan, 'r')\n",
    "    lin2 = op2.readlines()\n",
    "    op2.close()\n",
    "    \n",
    "    for j in range(len(lin2)):\n",
    "        if lin2[j][:2] == 'om':\n",
    "            om = lin2[j].split()[1]\n",
    "            omsig = lin2[j].split()[3]\n",
    "            stan_om_all_lowz.append(om)\n",
    "            stan_omsig_all_lowz.append(omsig)\n",
    "            \n",
    "            #print('om = ', om)\n",
    "            #print('omsig = ', omsig)\n",
    "            \n",
    "            \n",
    "        elif lin2[j][0] == 'w':\n",
    "            w = lin2[j].split()[1]\n",
    "            wsig = lin2[j].split()[3]\n",
    "            stan_w_all_lowz.append(w)\n",
    "            stan_wsig_all_lowz.append(wsig)\n",
    "            \n",
    "    Ia_code = 11\n",
    "        \n",
    "    flag_Ia = np.array(stats[0]) == Ia_code\n",
    "    \n",
    "    pop[Ia_code] = stats[1][flag_Ia][0]\n",
    "    perc[Ia_code] = round(100 * stats[1][flag_Ia][0]/data.shape[0], 2)\n",
    "    \n",
    "    if  len(stats[0]) == 2:\n",
    "        other_code = [item for item in stats[0] if item != Ia_code][0]\n",
    "        pop[other_code] = stats[1][~flag_Ia][0]\n",
    "        perc[other_code] = round(100 * stats[1][~flag_Ia][0]/data.shape[0], 2)\n",
    "            \n",
    "        pop_nIa_all.append(pop[other_code])\n",
    "        perc_nIa_all.append(perc[other_code])\n",
    "        other_index.append(other_code)\n",
    "        other_name.append(SNANA_names[other_code])\n",
    "        \n",
    "    elif len(stats[0]) > 2:\n",
    "        other_code = [item for item in stats[0] if item != Ia_code]\n",
    "        for item in range(flag_Ia.shape[0]):\n",
    "            if not flag_Ia[item]:\n",
    "                pop[stats[0][item]] = stats[1][item]\n",
    "                perc[stats[0][item]] = round(100 * stats[1][item]/data.shape[0], 2)\n",
    "                \n",
    "        pop_nIa_all.append([pop[item] for item in other_code])\n",
    "        perc_nIa_all.append([perc[item] for item in other_code])\n",
    "        other_index.append(other_code)\n",
    "        other_name.append([SNANA_names[i] for i in other_code])\n",
    "        \n",
    "    elif len(stats[0]) == 1:\n",
    "        other_code = '--'\n",
    "        pop_nIa_all.append(None)\n",
    "        perc_nIa_all.append(None)\n",
    "        other_index.append(None)\n",
    "        other_name.append(None)\n",
    "\n",
    "    pop_Ia_all.append(pop[Ia_code])\n",
    "    perc_Ia_all.append(perc[Ia_code])\n",
    "    \n",
    "    if '6' in case:\n",
    "        tot = 6000\n",
    "    elif '5' in case:\n",
    "        tot = 1500\n",
    "    elif '1000' in case:\n",
    "        tot = 1000\n",
    "    else:\n",
    "        tot = 3000\n",
    "    \n",
    "# this is where number of contaminants gets converted to fraction\n",
    "    cont = tot - pop[Ia_code]\n",
    "#     if '.' in case[:4]:\n",
    "#         cont = 0.01 * (100 - float(case[:4]))\n",
    "#     elif case[0] == 'p':\n",
    "#         cont = 0\n",
    "#     elif case[0] == 'r' or case[0] == 'f':\n",
    "#         cont = (tot - pop[Ia_code])/tot\n",
    "#     else:\n",
    "#         cont = 0.01 * (100 - float(case[:2]))\n",
    "    \n",
    "    if k in [1, '', 2, 3,4,5]:\n",
    "        for i in range(wdist_wfd.shape[0]):\n",
    "            if case[:-4] in wdist_wfd['FileA'].values[i] or \\\n",
    "                case[:-4] in wdist_wfd['FileB'].values[i]:\n",
    "                wdist_median.append(wdist_wfd['WassersteinDistanceMedian'].values[i])\n",
    "                break\n",
    "    else:\n",
    "        wdist_median.append(-99)\n",
    "    \n",
    "    metrics = classification_metrics(cont)\n",
    "    acc.append(metrics[0])\n",
    "    eff.append(metrics[1])\n",
    "    pur.append(metrics[2])\n",
    "    f1.append(metrics[3]) \n",
    "    f3.append(metrics[4])\n",
    "    \n",
    "        \n",
    "        \n",
    "data_all = {}\n",
    "data_all['case'] = names\n",
    "data_all['other_name'] = other_name\n",
    "data_all['other_code'] = other_index\n",
    "data_all['nIa'] = pop_Ia_all\n",
    "data_all['nothers'] = pop_nIa_all\n",
    "data_all['perc_Ia'] = perc_Ia_all\n",
    "data_all['perc_others'] = perc_nIa_all\n",
    "data_all['accuracy'] = acc\n",
    "data_all['efficiency'] = eff\n",
    "data_all['purity'] = pur\n",
    "data_all['fom1'] = f1\n",
    "data_all['fom3'] = f3\n",
    "data_all['wfit_w_lowz'] = wfit_w_all_lowz\n",
    "data_all['wfit_wsig_lowz'] = wfit_wsig_all_lowz\n",
    "data_all['wfit_om_lowz'] = wfit_om_all_lowz\n",
    "data_all['wfit_omsig_lowz'] = wfit_omsig_all_lowz\n",
    "data_all['stan_w_lowz'] = stan_w_all_lowz\n",
    "data_all['stan_wsig_lowz'] = stan_wsig_all_lowz\n",
    "data_all['stan_om_lowz'] = stan_om_all_lowz\n",
    "data_all['stan_omsig_lowz'] = stan_omsig_all_lowz\n",
    "data_all['WassersteinDistanceMedian'] = wdist_median\n",
    "\n",
    "data_all = pd.DataFrame(data_all)\n",
    "\n",
    "# add KLD\n",
    "if k == '':\n",
    "    fname1 = '/media/RESSPECT/data/PLAsTiCC/for_metrics/wfd/posteriors/klds.csv'\n",
    "    data_kld_wfd = pd.read_csv(fname1)\n",
    "\n",
    "    kld_wfd_column = []\n",
    "    for i in range(data_all.shape[0]):\n",
    "        name = data_all.iloc[i]['case']\n",
    "    \n",
    "        found = False\n",
    "        for j in range(data_kld_wfd.shape[0]):\n",
    "            if name in data_kld_wfd['path'].iloc[j]:\n",
    "                kld = data_kld_wfd['KLD'].iloc[j]\n",
    "                kld_wfd_column.append(kld)\n",
    "                found = True\n",
    "            \n",
    "        if not found:\n",
    "            kld_wfd_column.append(-99)\n",
    "        \n",
    "    data_all['KLD'] = kld_wfd_column\n",
    "else:\n",
    "    data_all['KLD'] = -99\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redo = True\n",
    "\n",
    "if redo:\n",
    "    data_all.to_csv('summary_cases_omprior_0.01_flat_redone' + str(k) +'.csv', index=False)\n",
    "    data_all.to_csv('/media2/RESSPECT2/data/posteriors_wfd/omprior_0.01_flat/summary_cases_omprior_0.01_flat_redone' + \\\n",
    "                str(k) + '.csv', index=False)\n",
    "else:\n",
    "    data_all.to_csv('summary_cases_omprior_0.01_flat_emille' + str(k) +'.csv', index=False)\n",
    "    data_all.to_csv('/media2/RESSPECT2/data/posteriors_wfd/omprior_0.01_flat/summary_cases_omprior_0.01_flat_emille' + \\\n",
    "                str(k) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "for name in cases:\n",
    "    copyfile(name[:-4] + '/test_mysamples' + str(k) + '/omprior_0.01_flat/results/' + \\\n",
    "             'stan_input_salt2mu_lowz_withbias_' + name,\n",
    "            '/media/RESSPECT/data/PLAsTiCC/for_metrics/ddf/distances/' + \\\n",
    "             'omprior_0.01_flat/emille_samples' + str(k) + '/stan_input_salt2mu_lowz_withbias_' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv('summary_cases.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_w = data_all['wfit_w'].values < 1000\n",
    "\n",
    "plt.figure(figsize=(16,15))\n",
    "\n",
    "plt.subplot(3,2,1)\n",
    "plt.hist(data_all['wfit_w'][~flag_w], color='darkblue')\n",
    "plt.hist(data_all['wfit_w'][flag_w], color='blue')\n",
    "plt.xlabel('w_from_wfit', fontsize=14)\n",
    "plt.ylabel('N', fontsize=14)\n",
    "\n",
    "\n",
    "plt.subplot(3,2,2)\n",
    "plt.hist(data_all['wfit_wsig'][~flag_w], color='darkblue')\n",
    "plt.hist(data_all['wfit_wsig'][flag_w], color='blue')\n",
    "plt.xlabel('wsig_from_wfit', fontsize=14)\n",
    "plt.ylabel('N', fontsize=14)\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "plt.hist(data_all['stan_w'][~flag_w], color='b')\n",
    "plt.hist(data_all['stan_w'][flag_w], color='darkblue')\n",
    "plt.xlabel('w_from_stan', fontsize=14)\n",
    "plt.ylabel('N', fontsize=14)\n",
    "\n",
    "plt.subplot(3,2,4)\n",
    "plt.hist(data_all['stan_wsig'][~flag_w], color='b')\n",
    "plt.hist(data_all['stan_wsig'][flag_w], color='darkblue')\n",
    "plt.xlabel('wsig_from_stan', fontsize=14)\n",
    "plt.ylabel('N', fontsize=14)\n",
    "\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "plt.hist(data_all['stan_w_lowz'][~flag_w], color='green', alpha=0.5)\n",
    "plt.hist(data_all['stan_w_lowz'][flag_w], color='brown')\n",
    "plt.xlabel('w_from_stan_with_lowz', fontsize=14)\n",
    "plt.ylabel('N', fontsize=14)\n",
    "\n",
    "plt.subplot(3,2,6)\n",
    "plt.hist(data_all['stan_wsig_lowz'][~flag_w], color='green', alpha=0.5)\n",
    "plt.hist(data_all['stan_wsig_lowz'][flag_w], color='brown')\n",
    "plt.xlabel('wsig_from_stan_with_lowz', fontsize=14)\n",
    "plt.ylabel('N', fontsize=14)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_col(x):\n",
    "    r = 'background-color: pink'\n",
    "    df1 = pd.DataFrame('', index=x.index, columns=x.columns)\n",
    "    df1.iloc[:, 5] = r\n",
    "    \n",
    "    return df1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdiff = data_all['wfit_w'].values - data_all['stan_w'].values\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(data_all['stan_w'][~flag_w], color='b')\n",
    "plt.hist(data_all['stan_w'][flag_w], color='darkblue')\n",
    "plt.xlabel('w_from_stan', fontsize=14)\n",
    "plt.ylabel('N', fontsize=14)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(wdiff[~flag_w], color='darkblue')\n",
    "plt.hist(wdiff[flag_w], color='b')\n",
    "plt.xlabel('wfit_w - stan_w', fontsize=14)\n",
    "plt.ylabel('N', fontsize=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import FlatLambdaCDM\n",
    "    \n",
    "cosmo = FlatLambdaCDM(H0=72, Om0=0.3)\n",
    "theor_dist = [cosmo.distmod(z).value for z in np.arange(0.001,1.5,0.005)]\n",
    "\n",
    "for name in cases[:1]:\n",
    "    \n",
    "    fname_fitres = name[:-4] + '/results/test_salt2mu_' + name[:-4] + '.fitres'\n",
    "    fitres = pd.read_csv(fname_fitres, comment='#', delim_whitespace=True)\n",
    "    \n",
    "    flag = fitres['SIM_TYPE_INDEX'].values == 11\n",
    "    z = fitres['SIM_ZCMB'].values\n",
    "    mu = fitres['MU'].values\n",
    "    muerr = fitres['MUERR'].values\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "        \n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(name, fontsize=26)\n",
    "\n",
    "    if sum(flag) > 0:\n",
    "        plt.errorbar(z[flag], mu[flag], yerr=muerr[flag], fmt='o', alpha=0.1, label='spec-Ia', color='blue')\n",
    "    \n",
    "    if sum(~flag) > 0:\n",
    "        plt.errorbar(z[~flag], mu[~flag], yerr=muerr[~flag], fmt='^', alpha=0.1, label='photo-Ia', color='green')\n",
    "       \n",
    "    plt.plot(np.arange(0.001, 1.5,0.005), theor_dist, label='w = -1', color='red')\n",
    "\n",
    "    w = str(cosmofit['w'].values[0])\n",
    "    if len(w) >= 6:\n",
    "        w1 = w[:6]\n",
    "    else:\n",
    "        w1 = w.ljust(6, '0')\n",
    "            \n",
    "    werr = str(cosmofit['wsig_marg'].values[0])\n",
    "    if len(werr) >= 6:\n",
    "        werr1 = werr[:5]\n",
    "    else:\n",
    "        werr1 = werr.ljust(5, '0')\n",
    "            \n",
    "    flag_case = data_all['case'].values == name[:-4]\n",
    "    ax.text(0.2, 32, 'stan = ' + str(data_all[flag_case]['stan_w'].values[0]) + r' $\\pm$ ' + str(data_all[flag_case]['stan_wsig'].values[0]), fontsize=20)\n",
    "    ax.text(0.2, 30, r'wfit = ' + w1 + r' $\\pm$ ' + werr1 , fontsize=20)\n",
    "        \n",
    "    ax.set_xlabel('redshift', fontsize=22)\n",
    "    ax.set_ylabel('mu', fontsize=22)\n",
    "    plt.legend(fontsize=22, loc='lower right')\n",
    "\n",
    "    plt.savefig('plots/distances/dist_' + name[:-4] + '.png')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in cases:\n",
    "\n",
    "    fname_fitres = name[:-4] + '/results/test_salt2mu_lowz_withbias_' + \\\n",
    "                   name[:-4] + '.fitres'\n",
    "    fitres = pd.read_csv(fname_fitres, comment='#', delim_whitespace=True)\n",
    "    \n",
    "    flag = np.logical_or(fitres['SIM_TYPE_INDEX'].values == 11, \n",
    "                         fitres['SIM_TYPE_INDEX'].values == 1)\n",
    "    z = fitres['SIM_ZCMB'].values\n",
    "    mu = fitres['MU'].values\n",
    "    muerr = fitres['MUERR'].values\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "        \n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(name, fontsize=26)\n",
    "\n",
    "    if sum(flag) > 0:\n",
    "        #data2 = pd.concat([data[flag], lowz], ignore_index=True)\n",
    "        plt.errorbar(z[flag], mu[flag], yerr=muerr[flag], fmt='o', \n",
    "                     alpha=0.1, label='spec-Ia', color='blue')\n",
    "    \n",
    "    if sum(~flag) > 0:\n",
    "        plt.errorbar(z[~flag], mu[~flag], yerr=muerr[~flag], fmt='^', \n",
    "                     alpha=0.1, label='photo-Ia', color='green')\n",
    "       \n",
    "    plt.plot(np.arange(0.001, 1.5,0.005), theor_dist, label='w = -1', color='red')\n",
    "\n",
    "    w = str(cosmofit_lowz['w'].values[0])\n",
    "    if len(w) >= 6:\n",
    "        w1 = w[:6]\n",
    "    else:\n",
    "        w1 = w.ljust(6, '0')\n",
    "            \n",
    "    werr = str(cosmofit_lowz['wsig_marg'].values[0])\n",
    "    if len(werr) >= 6:\n",
    "        werr1 = werr[:5]\n",
    "    else:\n",
    "        werr1 = werr.ljust(5, '0')\n",
    "            \n",
    "    flag_case = data_all['case'].values == name[:-4]\n",
    "    ax.text(0.2, 32, 'stan = ' + str(data_all[flag_case]['stan_w_lowz'].values[0]) + \\\n",
    "            r' $\\pm$ ' + \\\n",
    "            str(data_all[flag_case]['stan_wsig_lowz'].values[0]), fontsize=20)\n",
    "    ax.text(0.2, 30, r'wfit = ' + w1 + r' $\\pm$ ' + werr1 , fontsize=20)\n",
    "        \n",
    "    ax.set_xlabel('redshift', fontsize=22)\n",
    "    ax.set_ylabel('mu', fontsize=22)\n",
    "    plt.legend(fontsize=22, loc='lower right')\n",
    "\n",
    "    plt.savefig('plots/distances/dist_' + name[:-4] + '_lowz_withbias.png')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save samples for Alberto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "k = 5\n",
    "\n",
    "flist = os.listdir('.')\n",
    "flist.remove('summary_cases_omprior_0.01_flat_emille.csv')\n",
    "flist.remove('summary.ipynb')\n",
    "flist.remove('plots')\n",
    "flist.remove('.ipynb_checkpoints')\n",
    "flist.remove('perfect3000_0')\n",
    "flist.remove('perfect3000_I')\n",
    "flist.remove('perfect3000_II')\n",
    "flist.remove('perfect3000_III')\n",
    "flist.remove('perfect3000_IV')\n",
    "flist.remove('perfect3000_V')\n",
    "flist.remove('perfect3000_VI')\n",
    "flist.remove('perfect3000_VII')\n",
    "flist.remove('perfect3000_VIII')\n",
    "flist.remove('perfect3000_IX')\n",
    "flist.remove('random1000')\n",
    "flist.remove('random6000')\n",
    "flist.remove('summary_cases.csv')\n",
    "flist.remove('summary2.ipynb')\n",
    "#flist.remove('99SNIa1SNIax')\n",
    "for case in flist:\n",
    "\n",
    "    if os.path.isdir(case + '/test_mysamples' + str(k) + '/omprior_0.01_flat/'):\n",
    "        name = '/media/emille/git/COIN/RESSPECT_work/PLAsTiCC/metrics_paper/' + \\\n",
    "        'resspect_metric/posteriors/WFD/' + case + '/' + \\\n",
    "               'test_mysamples' + str(k) +'/omprior_0.01_flat/chains/chains_' + case + \\\n",
    "                '_lowz_withbias.pkl'\n",
    "        data = pd.read_pickle(name)\n",
    "        data2 = pd.DataFrame(data)\n",
    "        print(case, ' --- ', data2.shape[0])\n",
    "\n",
    "        data2.to_csv('/media/RESSPECT/data/PLAsTiCC/for_metrics/wfd/posteriors/' + \\\n",
    "                     'samples_emille' + str(k) + '/' + \\\n",
    "                    'chains_'  + case + '_lowz_withbias.csv.gz', index=False)\n",
    "        \n",
    "    else:\n",
    "        print('**** ', case, '*****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recidivator (Python 3)",
   "language": "python",
   "name": "recidivator_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
