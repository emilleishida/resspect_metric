{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the KLD from posterior samples of cosmological parameters\n",
    "\n",
    "_Alex I. Malz (GCCL@RUB)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "from scipy import stats as sps\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin with samples of $(w, \\Omega_{m})$ pairs, where one set of samples is defined as the reference sample corresponding to a best-case scenario of a 100% pure SN Ia data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # replace with reading in the data\n",
    "# def measure(n, w_bar, w_sig, Omm_bar,Omm_sig):\n",
    "#     \"Measurement model, return two coupled measurements.\"\n",
    "#     w = np.random.normal(loc=w_bar, scale=w_sig, size=n)\n",
    "#     Omm = np.random.normal(loc=Omm_bar, scale=Omm_sig, size=n)\n",
    "#     return w, Omm\n",
    "\n",
    "def measure(path, cols):\n",
    "    alldims = pkl.load(open(path, 'rb'))\n",
    "    return [alldims[col] for col in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refpath = '/media/RESSPECT/data/PLAsTiCC/SALT2mu_posteriors/perfect_classifier/chains_plasticc_perfect.pkl'\n",
    "comppath = '/media/RESSPECT/data/PLAsTiCC/SALT2mu_posteriors/static/DDF/train_10/batch_10/UncSampling/chains/chains_loop_99.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_ref, Omm_ref = measure(1000, -1., 0.1, 0.5, 0.1)\n",
    "# w_comp, Omm_comp = measure(1000, -1.1, 0.2, 0.25, 0.05)\n",
    "\n",
    "[w_ref, Omm_ref] = measure(refpath, ['w', 'om'])\n",
    "[w_comp, Omm_comp] = measure(comppath, ['w', 'om'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`chippr`](https://github.com/aimalz/chippr/) contains code for calculating the KLD of PDFs evaluated on a grid, so we start by fitting a 2D KDE to the samples.\n",
    "The PDFs must be $\\geq0$ over the entire range of the grid, so we make a grid based on the reference sample's range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with min and max of w, Omega in the set of reference samples\n",
    "ngrid_x = 100\n",
    "ngrid_y = 100\n",
    "xmin = w_ref.min()\n",
    "xmax = w_ref.max()\n",
    "ymin = Omm_ref.min()\n",
    "ymax = Omm_ref.max()\n",
    "\n",
    "w_grid, Omm_grid = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "dw = (xmax - xmin) / ngrid_x\n",
    "dOmm = (ymax - ymin) / ngrid_y\n",
    "# use meshgrid instead of mgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 2. * sys.float_info.min\n",
    "\n",
    "def safe_log(arr, threshold=eps):\n",
    "    \"\"\"\n",
    "    Takes the natural logarithm of an array that might contain zeros.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr: ndarray, float\n",
    "        array of values to be logged\n",
    "    threshold: float, optional\n",
    "        small, positive value to replace zeros and negative numbers\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logged: ndarray\n",
    "        logged values, with small value replacing un-loggable values\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    arr[arr < threshold] = threshold\n",
    "    logged = np.log(arr)\n",
    "    return logged\n",
    "\n",
    "def make_kde(Xgrid, Ygrid, Xsamps, Ysamps):\n",
    "    positions = np.vstack([Xgrid.ravel(), Ygrid.ravel()])\n",
    "    values = np.vstack([Xsamps, Ysamps])\n",
    "    kernel = sps.gaussian_kde(values)\n",
    "    Z = safe_log(np.reshape(kernel(positions).T, Xgrid.shape))\n",
    "    return Z\n",
    "# TODO: normalize up here before log!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_ref = make_kde(w_grid, Omm_grid, w_ref, Omm_ref)\n",
    "plt.imshow(kde_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with reading in other sets of posteriors\n",
    "kde_comp = make_kde(w_grid, Omm_grid, w_comp, Omm_comp)\n",
    "plt.imshow(kde_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the 2D PDFs, let's define the KLD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stolen from chippr\n",
    "def calculate_kld(lpe, lqe, dx, vb=True):\n",
    "    \"\"\"\n",
    "    Calculates the Kullback-Leibler Divergence between two N-dimensional PDFs \n",
    "    evaluated on a shared, regular grid (sorry, too lazy to deal with irregular grid)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lpe: numpy.ndarray, float\n",
    "        log-probability distribution evaluated on a grid whose distance from `q`\n",
    "        will be calculated.\n",
    "    lqe: numpy.ndarray, float\n",
    "        log-probability distribution evaluated on a grid whose distance to `p` will\n",
    "        be calculated.\n",
    "    dx: numpy.ndarray, float\n",
    "        separation of grid values in each dimension\n",
    "    vb: boolean\n",
    "        report on progress to stdout?\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dpq: float\n",
    "        the value of the Kullback-Leibler Divergence from `q` to `p`\n",
    "    \"\"\"\n",
    "    # Normalize the evaluations, so that the integrals can be done\n",
    "    gridnorm = np.ones_like(lpe) * np.prod(dx)\n",
    "    pe = np.exp(lpe)\n",
    "    qe = np.exp(lqe)\n",
    "#     print(np.prod(dx))\n",
    "#     print(gridnorm)\n",
    "    pi = pe * gridnorm\n",
    "    qi = qe * gridnorm\n",
    "    # (very approximately!) by simple summation:\n",
    "    pn = pe / pi\n",
    "    qn = qe / qi\n",
    "    # Compute the log of the normalized PDFs\n",
    "    logp = safe_log(pn)\n",
    "    logq = safe_log(qn)\n",
    "    # Calculate the KLD from q to p\n",
    "    Dpq = np.sum(pn * (logp - logq))\n",
    "    return Dpq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate it for our reference sample and a comparison sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_kld(kde_ref, kde_comp, np.array([dw, dOmm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recidivator (Python 3)",
   "language": "python",
   "name": "recidivator_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
