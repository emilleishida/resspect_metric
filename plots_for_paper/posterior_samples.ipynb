{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of posterior samples\n",
    "\n",
    "_Kara Ponder (SLAC-->?), Emille Ishida (Clermont-Ferrand), Alex Malz (GCCL@RUB)_\n",
    "\n",
    "plagiarized from `Combination_plots.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import glob\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import scipy.stats as sps\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kara's plotting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# import resspect.cosmo_metric_utils as cmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shapes = {'SNIa-91bg': 'o',\n",
    "              'SNIax': 's',\n",
    "              'SNII': 'd',\n",
    "              'SNIbc': 'X',\n",
    "              'SLSN-I': 'v',\n",
    "              'AGN': '^',\n",
    "              'TDE': '<',\n",
    "              'KN': '>',\n",
    "              'CART': 'v'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color map\n",
    "rainbow = cm = plt.get_cmap('plasma_r')\n",
    "cNorm  = colors.LogNorm(vmin=1, vmax=52) #colors.Normalize(vmin=0, vmax=50)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=rainbow)\n",
    "color_map = scalarMap.to_rgba(np.arange(1, 52))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDF summary on the COIN server:\n",
    "file_extensions = {'ddf': 'DDF', \n",
    "                   'wfd': 'WFD'\n",
    "                  }\n",
    "ktot = 5\n",
    "kglob = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cases(field, k=''):\n",
    "    if k == '':\n",
    "        k = '0'\n",
    "    dirname = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/'+field+'/v'+k+'/samples/'\n",
    "    cases = os.listdir(dirname)\n",
    "    cases.remove('random1500.csv')\n",
    "    cases.remove('random6000.csv')\n",
    "    cases.remove('fiducial1500.csv')\n",
    "    cases.remove('fiducial6000.csv')\n",
    "    cases.remove('perfect6000.csv')\n",
    "    cases.remove('perfect1500.csv')\n",
    "    print(cases)\n",
    "    return(cases, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases, dirnames = {}, {}\n",
    "for file_extension in file_extensions:\n",
    "    cases[file_extension], dirnames[file_extension] = get_cases(file_extensions[file_extension])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_remap_dict(file_extension):\n",
    "    if 'wfd' in file_extension:\n",
    "        remap_dict = OrderedDict({\n",
    "                              'perfect3000': 'Perfect', \n",
    "                              'fiducial3000': 'Fiducial', \n",
    "                              'random3000': 'Random',\n",
    "                              'all_objs_survived_SALT2_DDF' : 'All SALT',\n",
    "                              'all_objs_survived_SALT2_WFD': 'All SALT',\n",
    "                              '50SNIa50SNII': 'SN-II 50',\n",
    "                              '68SNIa32SNII': 'SN-II 32',\n",
    "                              '72SNIa28SNII': 'SN-II 28',\n",
    "                              '75SNIa25SNII': 'SN-II 25', \n",
    "                              '90SNIa10SNII': 'SN-II 10',\n",
    "                              '95SNIa5SNII': 'SN-II 5',\n",
    "                              '98SNIa2SNII': 'SN-II 2',\n",
    "                              '99SNIa1SNII': 'SN-II 1',\n",
    "                              '50SNIa50SNIbc': 'SN-Ibc 50',\n",
    "                              '68SNIa32SNIbc': 'SN-Ibc 32',\n",
    "                              '75SNIa25SNIbc': 'SN-Ibc 25',\n",
    "                              '83SNIa17SNIbc': 'SN-Ibc 17',\n",
    "                              '90SNIa10SNIbc': 'SN-Ibc 10',\n",
    "                              '95SNIa5SNIbc': 'SN-Ibc 5',\n",
    "                              '98SNIa2SNIbc': 'SN-Ibc 2',\n",
    "                              '99SNIa1SNIbc': 'SN-Ibc 1',\n",
    "                              '50SNIa50SNIax': 'SN-Iax 50',\n",
    "                              '68SNIa32SNIax': 'SN-Iax 32',\n",
    "                              '75SNIa25SNIax': 'SN-Iax 25',\n",
    "                              '86SNIa14SNIax': 'SN-Iax 14',\n",
    "                              '90SNIa10SNIax': 'SN-Iax 10',\n",
    "                              '94SNIa6SNIax': 'SN-Iax 6',\n",
    "                              '95SNIa5SNIax': 'SN-Iax 5',\n",
    "                              '97SNIa3SNIax': 'SN-Iax 3',\n",
    "                              '98SNIa2SNIax': 'SN-Iax 2',\n",
    "                              '99SNIa1SNIax': 'SN-Iax 1',\n",
    "                              '71SNIa29SNIa-91bg': 'SN-Ia-91bg 29',\n",
    "                              '75SNIa25SNIa-91bg': 'SN-Ia-91bg 25',\n",
    "                              '90SNIa10SNIa-91bg': 'SN-Ia-91bg 10',\n",
    "                              '95SNIa5SNIa-91bg': 'SN-Ia-91bg 5',\n",
    "                              '98SNIa2SNIa-91bg': 'SN-Ia-91bg 2',\n",
    "                              '99SNIa1SNIa-91bg': 'SN-Ia-91bg 1',\n",
    "                              '99.8SNIa0.2SNIa-91bg': 'SN-Ia-91bg 0.2',\n",
    "                              '57SNIa43AGN': 'AGN 43',\n",
    "                              '75SNIa25AGN': 'AGN 25',\n",
    "                              '90SNIa10AGN': 'AGN 10',\n",
    "                              '94SNIa6AGN': 'AGN 6',\n",
    "                              '95SNIa5AGN': 'AGN 5',\n",
    "                              '98SNIa2AGN': 'AGN 2',\n",
    "                              '99SNIa1AGN': 'AGN 1',\n",
    "                              '99.9SNIa0.1AGN': 'AGN 0.1',\n",
    "                              '83SNIa17SLSN-I': 'SLSN-I 17',\n",
    "                              '90SNIa10SLSN-I': 'SLSN-I 10',\n",
    "                              '95SNIa5SLSN-I': 'SLSN-I 5',\n",
    "                              '98SNIa2SLSN-I': 'SLSN-I 2',\n",
    "                              '99SNIa1SLSN-I': 'SLSN-I 1',\n",
    "                              '99SNIa1SLSN': 'SLSN 1',\n",
    "                              '99.9SNIa0.1SLSN': 'SLSN-I 0.1',\n",
    "                              '95SNIa5TDE': 'TDE 5',\n",
    "                              '98SNIa2TDE': 'TDE 2',\n",
    "                              '99SNIa1TDE': 'TDE 1',\n",
    "                              '99.6SNIa0.4TDE': 'TDE 0.4',\n",
    "                              '99.1SNIa0.9CART': 'CART 0.9',\n",
    "                              '99.7SNIa0.3CART': 'CART 0.3'\n",
    "                  })\n",
    "    else:\n",
    "        remap_dict = OrderedDict({\n",
    "                          'perfect3000': 'Perfect', \n",
    "                          'fiducial3000': 'Fiducial', \n",
    "                          'random3000': 'Random',\n",
    "                          'all_objs_survived_SALT2_DDF' : 'All SALT',\n",
    "                          'all_objs_survived_SALT2_WFD': 'All SALT',\n",
    "                          '50SNIa50SNII': 'SN-II 50',\n",
    "                          '68SNIa32SNII': 'SN-II 32',\n",
    "                          '72SNIa28SNII': 'SN-II 28',\n",
    "                          '75SNIa25SNII': 'SN-II 25', \n",
    "                          '90SNIa10SNII': 'SN-II 10',\n",
    "                          '95SNIa5SNII': 'SN-II 5',\n",
    "                          '98SNIa2SNII': 'SN-II 2',\n",
    "                          '99SNIa1SNII': 'SN-II 1',\n",
    "                          '50SNIa50SNIbc': 'SN-Ibc 50',\n",
    "                          '68SNIa32SNIbc': 'SN-Ibc 32',\n",
    "                          '75SNIa25SNIbc': 'SN-Ibc 25',\n",
    "                          '83SNIa17SNIbc': 'SN-Ibc 17',\n",
    "                          '90SNIa10SNIbc': 'SN-Ibc 10',\n",
    "                          '92SNIa8SNIbc': 'SN-Ibc 8',\n",
    "                          '95SNIa5SNIbc': 'SN-Ibc 5',\n",
    "                          '98SNIa2SNIbc': 'SN-Ibc 2',\n",
    "                          '99SNIa1SNIbc': 'SN-Ibc 1',\n",
    "                          '50SNIa50SNIax': 'SN-Iax 50',\n",
    "                          '68SNIa32SNIax': 'SN-Iax 32',\n",
    "                          '75SNIa25SNIax': 'SN-Iax 25',\n",
    "                          '86SNIa14SNIax': 'SN-Iax 14',\n",
    "                          '90SNIa10SNIax': 'SN-Iax 10',\n",
    "                          '91SNIa9SNIax': 'SN-Iax 9',\n",
    "                          '94SNIa6SNIax': 'SN-Iax 6',\n",
    "                          '95SNIa5SNIax': 'SN-Iax 5',\n",
    "                          '97SNIa3SNIax': 'SN-Iax 3',\n",
    "                          '98SNIa2SNIax': 'SN-Iax 2',\n",
    "                          '99SNIa1SNIax': 'SN-Iax 1',\n",
    "                          '99.1SNIa0.9CART': 'CART 0.9',\n",
    "                          '99.7SNIa0.3CART': 'CART 0.3',\n",
    "                          '71SNIa29SNIa-91bg': 'SN-Ia-91bg 29',\n",
    "                          '75SNIa25SNIa-91bg': 'SN-Ia-91bg 25',\n",
    "                          '90SNIa10SNIa-91bg': 'SN-Ia-91bg 10',\n",
    "                          '95SNIa5SNIa-91bg': 'SN-Ia-91bg 5',\n",
    "                          '98SNIa2SNIa-91bg': 'SN-Ia-91bg 2',\n",
    "                          '99SNIa1SNIa-91bg': 'SN-Ia-91bg 1',\n",
    "                          '99.8SNIa0.2SNIa-91bg': 'SN-Ia-91bg 0.2',\n",
    "                          '57SNIa43AGN': 'AGN 43',\n",
    "                          '75SNIa25AGN': 'AGN 25',\n",
    "                          '90SNIa10AGN': 'AGN 10',\n",
    "                          '94SNIa6AGN': 'AGN 6',\n",
    "                          '95SNIa5AGN': 'AGN 5',\n",
    "                          '98SNIa2AGN': 'AGN 2',\n",
    "                          '99SNIa1AGN': 'AGN 1',\n",
    "                          '99.9SNIa0.1AGN': 'AGN 0.1',\n",
    "                          '83SNIa17SLSN-I': 'SLSN-I 17',\n",
    "                          '90SNIa10SLSN-I': 'SLSN-I 10',\n",
    "                          '95SNIa5SLSN-I': 'SLSN-I 5',\n",
    "                          '98SNIa2SLSN-I': 'SLSN-I 2',\n",
    "                          '99SNIa1SLSN-I': 'SLSN-I 1',\n",
    "                          '99SNIa1SLSN': 'SLSN 1',\n",
    "                          '99.9SNIa0.1SLSN': 'SLSN-I 0.1',\n",
    "                          '95SNIa5TDE': 'TDE 5',\n",
    "                          '98SNIa2TDE': 'TDE 2',\n",
    "                          '99SNIa1TDE': 'TDE 1',\n",
    "                          '99.6SNIa0.4TDE': 'TDE 0.4',\n",
    "              })\n",
    "    return(remap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remap_dicts = {}\n",
    "for file_extension in file_extensions:\n",
    "    thing = make_remap_dict(file_extensions[file_extension])\n",
    "    tempdict = {}\n",
    "    for case in cases[file_extension]:\n",
    "        if case[:-4] in thing.keys():\n",
    "            tempdict[case[:-4]] = thing[case[:-4]]\n",
    "        else:\n",
    "            print(case)\n",
    "    remap_dicts[file_extension] = tempdict#{thing[case[:-4]] for case in cases[file_extension]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the percent contaminated to the colormap.\n",
    "## size corresponds to remap_dict\n",
    "def make_color_nums(file_extension):\n",
    "    if 'wfd' in file_extension:\n",
    "        color_num = np.array([1, 1, 1, 1, 1, 1,                    # Special\n",
    "                           50, 32, 28, 25, 10, 5, 2, 1,   # II\n",
    "                           50, 32, 25, 17, 10, 5, 2, 1,               # Ibc\n",
    "                           50, 32, 25, 14, 10, 6, 5, 3, 2, 1,         # Iax\n",
    "                           29, 25, 10, 5, 2, 1, 1,                          # 91bg\n",
    "                           43, 25, 10, 6, 5, 2, 1, 1,                      # AGN\n",
    "                           17, 10, 5, 2, 1, 1, 1,                            # SLSN\n",
    "                           5, 2, 1, 1,                            # TDE\n",
    "                           1, 1,                           # CART\n",
    "                          ]) #+ 1                    \n",
    "    else:\n",
    "        color_num = np.array([1, 1, 1, 1, 1, 1,                    # Special\n",
    "                           50, 32, 28, 25, 10, 5, 2, 1,   # II\n",
    "                           50, 32, 25, 17, 10, 8, 5, 2, 1,               # Ibc\n",
    "                           50, 32, 25, 14, 10, 9, 6, 5, 3, 2, 1,         # Iax\n",
    "                           1, 1,                           # CART\n",
    "                           29, 25, 10, 5, 2, 1, 1,                          # 91bg\n",
    "                           43, 25, 10, 6, 5, 2, 1, 1,                      # AGN\n",
    "                           17, 10, 5, 2, 1, 1, 1,                            # SLSN\n",
    "                           5, 2, 1, 1,                            # TDE\n",
    "                          ]) #+ 1   \n",
    "    return(color_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_nums = {}\n",
    "for file_extension in file_extensions:\n",
    "    color_nums[file_extension] = make_color_nums(file_extensions[file_extension])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color map\n",
    "rainbow = cm = plt.get_cmap('plasma_r')\n",
    "cNorm  = colors.LogNorm(vmin=1, vmax=52) #colors.Normalize(vmin=0, vmax=50)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=rainbow)\n",
    "color_map = scalarMap.to_rgba(np.arange(1, 52))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the curve(s)\n",
    "\n",
    "KDE for each set of posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 2. * sys.float_info.min\n",
    "\n",
    "def safe_log(arr, threshold=eps):\n",
    "    \"\"\"\n",
    "    Takes the natural logarithm of an array that might contain zeros.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr: ndarray, float\n",
    "        array of values to be logged\n",
    "    threshold: float, optional\n",
    "        small, positive value to replace zeros and negative numbers\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logged: ndarray\n",
    "        logged values, with small value replacing un-loggable values\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    arr[arr < threshold] = threshold\n",
    "    logged = np.log(arr)\n",
    "    return logged\n",
    "\n",
    "def make_grid(x, y, x_ngrid=100, y_ngrid=100):\n",
    "    x_min = x.min()#-1.2\n",
    "    x_max = x.max()#-0.8\n",
    "    y_min = y.min()#0.2\n",
    "    y_max = y.max()#0.4\n",
    "\n",
    "    x_grid, y_grid = np.mgrid[x_min:x_max:x_ngrid*1.j, y_min:y_max:y_ngrid*1.j]\n",
    "    x_vec, y_vec = x_grid[:, 0], y_grid[0, :]\n",
    "    dx = (x_max - x_min) / (x_ngrid - 1)\n",
    "    dy = (y_max - y_min) / (y_ngrid - 1)\n",
    "\n",
    "    return(((x_min, y_min), (x_max, y_max)), (x_grid, y_grid), (x_vec, y_vec), (dx, dy))\n",
    "\n",
    "def make_kde(Xgrid, Ygrid, Xsamps, Ysamps, to_log=False, save=None, one_d=True):\n",
    "    if not one_d:\n",
    "        positions = np.vstack([Xgrid.ravel(), Ygrid.ravel()])\n",
    "        values = np.vstack([Xsamps, Ysamps])\n",
    "        kernel = sps.gaussian_kde(values, bw_method='scott')\n",
    "        Z = np.reshape(kernel(positions).T, Xgrid.shape)\n",
    "    else:\n",
    "        positions = Xgrid.T[0]\n",
    "        values = Xsamps\n",
    "        kernel = sps.gaussian_kde(values, bw_method='scott')\n",
    "        Z = kernel(positions)\n",
    "    \n",
    "    if to_log:\n",
    "        return safe_log(Z)\n",
    "    else:\n",
    "        return Z\n",
    "#     if save is not None:\n",
    "# TODO: normalize up here before log!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# alloutputs = pd.DataFrame(columns=['path', 'KLD'])\n",
    "#     # make reference sample\n",
    "# with gzip.open(fullpath+refname) as reffn:\n",
    "#     flatref = pd.read_csv(reffn)\n",
    "# [w_ref, Omm_ref] = [flatref['w'], flatref['om']]\n",
    "# ref_extrema, ref_grids, ref_vecs, ref_ds = make_grid(w_ref, Omm_ref)\n",
    "# (w_vec, Omm_vec) = ref_vecs\n",
    "# (dw, dOmm) = ref_ds\n",
    "# ((xmin, ymin), (xmax, ymax)) = ref_extrema\n",
    "# (w_grid, Omm_grid) = ref_grids\n",
    "# d_ref = {'w': dw, 'Omm': dOmm}\n",
    "# grid_ref = {'w': w_grid, 'Omm': Omm_grid}\n",
    "# kde_ref = make_kde(w_grid, Omm_grid, w_ref, Omm_ref, one_d=True, to_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posteriors(field, k, casename, nsn, withlowz=True):\n",
    "    case = casename+str(nsn)\n",
    "    filename = 'chains_'+case\n",
    "    if withlowz:\n",
    "        filename = filename+'_lowz_withbias'\n",
    "    path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/'+file_extensions[field]+'/v'+str(k)+'/posteriors/pkl/'\n",
    "#     if field == 'ddf':\n",
    "# #         if k == '':\n",
    "# #             k = 0\n",
    "#         path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/DDF/v'+str(k)+'/posteriors/pkl/'\n",
    "# #             path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/ddf/posteriors/samples_emille/'\n",
    "# #             ext = '.csv.gz'\n",
    "# #         else:\n",
    "# #             path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/ddf/emille_samples'+str(k)+'/posteriors/'\n",
    "    ext = '.pkl'\n",
    "#     elif field == 'wfd':\n",
    "#         path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/wfd/posteriors/samples_emille'+str(k)+'/'\n",
    "#         ext = '.csv.gz'\n",
    "    samppathname = path_pre+filename+ext\n",
    "#     print(samppathname)\n",
    "    if ext == '.csv.gz':\n",
    "        with gzip.open(samppathname) as sampfile:\n",
    "            sampdata = pd.read_csv(sampfile)\n",
    "    elif ext == '.pkl':\n",
    "        with open(samppathname, 'rb') as sampfile:\n",
    "            sampdata = pkl.load(sampfile)\n",
    "#     print(sampdata)\n",
    "    return([sampdata['w'], sampdata['om']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cases = ['perfect', 'random', 'fiducial']\n",
    "ktot = 6\n",
    "kmin = 1\n",
    "samp_sizes = [1500, 3000, 6000]\n",
    "ngrid = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdata = {}\n",
    "for field in file_extensions:\n",
    "    outdata[field] = {}\n",
    "    for casename in null_cases:\n",
    "        outdata[field][casename] = np.empty((ktot, len(samp_sizes), 2, ngrid))\n",
    "        for k in range(kmin, ktot, 1):\n",
    "            for i, nsn in enumerate(samp_sizes):\n",
    "                kpass = k\n",
    "                [w_comp, Omm_comp] = get_posteriors(field, kpass, casename, nsn, withlowz=True)#[sampdata['w'], sampdata['om']]\n",
    "                comp_extrema, comp_grids, comp_vecs, comp_ds = make_grid(w_comp, Omm_comp)\n",
    "                (w_grid, Omm_grid) = comp_grids\n",
    "                kde_comp = make_kde(w_grid, Omm_grid, w_comp, Omm_comp, one_d=True, to_log=True)\n",
    "                outdata[field][casename][k][i] = np.array([w_grid.T[0], kde_comp])\n",
    "with open('default_kdes.pkl', 'wb') as outfile:\n",
    "    pkl.dump(outdata, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdata = {}\n",
    "for field in file_extensions:\n",
    "    outdata[field] = {}\n",
    "    for casename in cases[field]:\n",
    "        outdata[field][casename[:-4]] = np.empty((2, ngrid))\n",
    "        k = '1'\n",
    "        nsn = ''\n",
    "        [w_comp, Omm_comp] = get_posteriors(field, k, casename[:-4], nsn, withlowz=True)#[sampdata['w'], sampdata['om']]\n",
    "        comp_extrema, comp_grids, comp_vecs, comp_ds = make_grid(w_comp, Omm_comp)\n",
    "        (w_grid, Omm_grid) = comp_grids\n",
    "        kde_comp = make_kde(w_grid, Omm_grid, w_comp, Omm_comp, one_d=True, to_log=True)\n",
    "        outdata[field][casename[:-4]] = np.array([w_grid.T[0], kde_comp])\n",
    "with open('testcase_kdes.pkl', 'wb') as outfile:\n",
    "    pkl.dump(outdata, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make plot(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_colors = {'perfect': 'k', 'random': 'tab:red', 'fiducial': 'tab:blue'}\n",
    "def_styles = {'1500': ':', '3000': '-', '6000': '--'}#{'DDF': '-', 'WFD': '--'}\n",
    "# def_lowz = {'withbias': , 'nobias':}\n",
    "\n",
    "with open('default_kdes.pkl', 'rb') as infile:\n",
    "    indata = pkl.load(infile)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)    \n",
    "for j, field in enumerate(file_extensions):\n",
    "    for casename in null_cases:\n",
    "        ax[j].scatter([0], [0], label=casename, color=def_colors[casename])\n",
    "        for i, nsn in enumerate(samp_sizes):\n",
    "            for k in range(ktot-1, ktot):\n",
    "                w_grid, kde_comp = indata[field][casename][k][i]#[w_grid, kde_comp] = indata[casename]\n",
    "#                 if k == 0:\n",
    "#                     lw_boost = 2\n",
    "# #                     print(kde_comp)\n",
    "#                 else:\n",
    "#                     lw_boost = 1\n",
    "                ax[j].plot(w_grid, np.exp(kde_comp),# label=field+casename, \n",
    "                linestyle=def_styles[str(nsn)], color=def_colors[casename], alpha=0.75, linewidth=1)\n",
    "    for nsn in samp_sizes:\n",
    "        ax[j].plot([0], [0], label=str(nsn), \n",
    "                 linestyle=def_styles[str(nsn)], color='tab:green', alpha=0.75, linewidth=1) \n",
    "    ax[j].text(-1., 30., file_extensions[field], fontsize=20)\n",
    "    ax[j].set_yticks([])\n",
    "    if j == 0:\n",
    "        ax[j].set_xticks([])\n",
    "    # plt.title(field+k)\n",
    "    if j == 1:\n",
    "        ax[j].legend(loc='upper left')#, ncol=2)\n",
    "        ax[j].set_xlabel(r'$w$')\n",
    "    ax[j].set_xlim(-1.2, -0.95)\n",
    "fig.subplots_adjust(wspace=0., hspace=0.)\n",
    "plt.savefig('dists_null.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: investigate the runs that are flat KDEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: also with and without bias of lowz sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates, contaminants = {}, {}\n",
    "for field in file_extensions:\n",
    "    rate, contaminant = {}, {}\n",
    "    for key in remap_dicts[field]:\n",
    "        postsplit = remap_dicts[field][key].split()\n",
    "        if len(postsplit) > 1:\n",
    "            name = postsplit[0]\n",
    "            perc = float(postsplit[-1])\n",
    "#         rate[name] = perc\n",
    "            rate[key] = perc\n",
    "            contaminant[key] = name\n",
    "    rates[field] = rate\n",
    "    contaminants[field] = contaminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in file_extensions:\n",
    "    plt.hist(rates[field].values(), bins=25, alpha=0.5, label=field)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: automate dividing into panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [0., 1., 2., 5., 7.5, 15., 50.]\n",
    "cutofflabels = ['<1%', '1%', '2%', '5%', '10%', '25%']\n",
    "\n",
    "panel_groups = {}\n",
    "for field in file_extensions:\n",
    "    panel_groups[field] = {j: [] for j in range(6)}\n",
    "#     print(field)\n",
    "    for i, casefn in enumerate(rates[field]):\n",
    "        casename = casefn#[:-4]\n",
    "        rate = rates[field][casename]\n",
    "#         for j, cutoff in enumerate(cutoffs[:-1]):\n",
    "#             if rate > cutoffs[j] and rate < :\n",
    "#                 panel_groups[field][0].append(casename)\n",
    "        if rate > 0. and rate < 1.:\n",
    "            panel_groups[field][0].append(casename)\n",
    "#             print((casename, rates[field][casename], 0))\n",
    "        elif rate >= 1. and rate < 2.:\n",
    "            panel_groups[field][1].append(casename)\n",
    "#             print((casename, rates[field][casename], 1))\n",
    "        elif rate >= 2. and rate < 5.:\n",
    "            panel_groups[field][2].append(casename)\n",
    "#             print((casename, rates[field][casename], 1))\n",
    "        elif rate >= 5. and rate < 7.5:\n",
    "            panel_groups[field][3].append(casename)\n",
    "#             print((casename, rates[field][casename], 5))\n",
    "        elif rate >= 7.5 and rate <= 15.:\n",
    "            panel_groups[field][4].append(casename)\n",
    "#             print((casename, rates[field][casename], 10))  \n",
    "        elif rate >= 15. and rate <= 50.:\n",
    "            panel_groups[field][5].append(casename)\n",
    "#             print((casename, rates[field][casename], 25))    \n",
    "#         else:\n",
    "#             print((casename, rates[field][casename], 'big'))\n",
    "print(panel_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_set = set(contaminants['ddf'].values())\n",
    "# if len(file_extensions) > 1:\n",
    "#     for field in file_extensions[1:]:\n",
    "#         base_contaminant_set = set.union(base_contaminant_set, set(contaminants[field].values()))\n",
    "wfd_set = set(contaminants['wfd'].values())\n",
    "all_contaminants = set.union(ddf_set, wfd_set)\n",
    "# base_contaminant_set#\n",
    "\n",
    "color_list = OrderedDict({contaminant: plt.cm.tab10(i) for i, contaminant in enumerate(all_contaminants)})\n",
    "\n",
    "contaminant_colors = {}\n",
    "for field in file_extensions:\n",
    "    contaminant_colors[field] = {}\n",
    "    for i, contaminant in enumerate(contaminants[field]):\n",
    "        contaminant_colors[field][contaminant] = color_list[contaminants[field][contaminant]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def_colors = {'perfect': 'k', 'random': 'tab:red', 'fiducial': 'tab:blue'}\n",
    "# def_styles = {'1500': ':', '3000': '-', '6000': '--'}#{'DDF': '-', 'WFD': '--'}\n",
    "# def_lowz = {'withbias': , 'nobias':}\n",
    "\n",
    "with open('testcase_kdes.pkl', 'rb') as infile:\n",
    "    indata = pkl.load(infile)\n",
    "\n",
    "for field in file_extensions:\n",
    "    if field == 'wfd':\n",
    "        table_loc = '/media2/RESSPECT2/data/posteriors_wfd/omprior_0.01_flat/summary_cases_omprior_0.01_flat_emille.csv'\n",
    "    else:\n",
    "        table_loc = '/media2/RESSPECT2/data/posteriors_ddf/omprior_0.01_flat/summary_cases_emille.csv'\n",
    "    df = pd.read_csv(table_loc)\n",
    "    df = df.set_index('case')\n",
    "#     print((field, df.index))\n",
    "    fig = pylab.figure(figsize=(15, 10))\n",
    "    bigAxes = pylab.axes(frameon=False)     # hide frame\n",
    "    bigAxes.set_xticks([])                        # don't want to see any ticks on this axis\n",
    "    bigAxes.set_yticks([])\n",
    "#     bigAxes.set_xlabel(r'$-1.3 < w < -0.9$', fontsize=20)\n",
    "    bigAxes.set_title(file_extensions[field], fontsize=20)\n",
    "    numrows=2\n",
    "    numcols=3\n",
    "#     fig, ax = plt.subplots(2, 3, figsize=(15, 10))\n",
    "#     fig.suptitle(file_extensions[field])\n",
    "    for i in range(len(panel_groups[field])):\n",
    "        per_panel_contaminants = [contaminants[field][panel_groups[field][i][j]] \n",
    "                                  for j in range(len(panel_groups[field][i]))]\n",
    "        uniques, unique_ind = np.unique(per_panel_contaminants, return_index=True)\n",
    "        ax = fig.add_subplot(numrows,numcols,i+1)\n",
    "#         ax.spines['right'].set_visible(False)\n",
    "#         ax.spines['top'].set_visible(False)\n",
    "#         position = ax.get_position()\n",
    "#         position.x0 += 0.01\n",
    "#         position.y0 += 0.02\n",
    "#         position.x1 += 0.01\n",
    "#         position.y1 += 0.02\n",
    "#         ax.set_position(position)\n",
    "        stylecount = 0\n",
    "        ax.text(-0.95, 35., cutofflabels[i], fontsize=18, horizontalalignment='right', verticalalignment='center')\n",
    "        for j, val in enumerate(unique_ind):\n",
    "            casename = panel_groups[field][i][val]\n",
    "            w_grid, kde_comp = indata[field][casename]#[w_grid, kde_comp] = indata[casename]\n",
    "            ax.plot(w_grid, np.exp(kde_comp), color=contaminant_colors[field][casename], label=per_panel_contaminants[val]) \n",
    "#         plt.title(field)\n",
    "            ax.vlines(df['wfit_w_lowz'].loc[casename], 0, 40, color=contaminant_colors[field][casename], linestyle=':')\n",
    "        ax.legend(fontsize=16, loc='upper left', bbox_to_anchor=(-0.025, 1.025))#, ncol=2)\n",
    "        ax.set_xlabel(r'$w$', fontsize=18)\n",
    "        ax.set_ylim(0., 40.)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_yticklabels([])\n",
    "#         ax.set_xlim(-1.3, -0.9)\n",
    "        ax.set_xticks([-1.2, -1.1, -1.])\n",
    "#         ax.set_xticklabels([])\n",
    "#     plt.savefig(file_extensions[field]+'dists_null.png')\n",
    "    \n",
    "    fig.subplots_adjust(wspace=0., hspace=0.)\n",
    "    pylab.savefig(file_extensions[field]+'combos.png',format='png', bbox_inches='tight', pad_inches=0, dpi=250)\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: polish these for paper\n",
    "- linestyle for contamination rate if more than one with same contaminant per panel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recidivator (Python 3)",
   "language": "python",
   "name": "recidivator_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
