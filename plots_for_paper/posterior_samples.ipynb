{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of posterior samples\n",
    "\n",
    "_Kara Ponder (SLAC-->?), Emille Ishida (Clermont-Ferrand), Alex Malz (GCCL@RUB)_\n",
    "\n",
    "plagiarized from `Combination_plots.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import glob\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import scipy.stats as sps\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kara's plotting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# import resspect.cosmo_metric_utils as cmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shapes = {'SNIa-91bg': 'o',\n",
    "              'SNIax': 's',\n",
    "              'SNII': 'd',\n",
    "              'SNIbc': 'X',\n",
    "              'SLSN-I': 'v',\n",
    "              'AGN': '^',\n",
    "              'TDE': '<',\n",
    "              'KN': '>',\n",
    "              'CART': 'v'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color map\n",
    "rainbow = cm = plt.get_cmap('plasma_r')\n",
    "cNorm  = colors.LogNorm(vmin=1, vmax=52) #colors.Normalize(vmin=0, vmax=50)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=rainbow)\n",
    "color_map = scalarMap.to_rgba(np.arange(1, 52))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDF summary on the COIN server:\n",
    "file_extensions = {'ddf': 'DDF', \n",
    "                   'wfd': 'WFD'\n",
    "                  }\n",
    "ktot = 5\n",
    "kglob = ''\n",
    "nobjs = '3000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cases(field, k='', nobjs=3000):\n",
    "    if k == '':\n",
    "        k = '0'\n",
    "    dirname = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data3/'+field+'/results/v'+k+'/' + str(nobjs) + '/samples/'\n",
    "    cases = os.listdir(dirname)\n",
    "    #cases.remove('random1500.csv')\n",
    "    #cases.remove('random6000.csv')\n",
    "    #cases.remove('fiducial1500.csv')\n",
    "    #cases.remove('fiducial6000.csv')\n",
    "    #cases.remove('perfect6000.csv')\n",
    "    #cases.remove('perfect1500.csv')\n",
    "    \n",
    "    if '.ipynb_checkpoints' in cases:\n",
    "        cases.remove('.ipynb_checkpoints')\n",
    "        \n",
    "    #print(cases)\n",
    "    return(cases, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases, dirnames = {}, {}\n",
    "for file_extension in file_extensions:\n",
    "    cases[file_extension], dirnames[file_extension] = get_cases(file_extensions[file_extension])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_remap_dict(file_extension):\n",
    "    if 'wfd' in file_extension:\n",
    "        remap_dict = OrderedDict({\n",
    "                              'perfect3000': 'Perfect', \n",
    "                              'fiducial3000': 'Fiducial', \n",
    "                              'random3000': 'Random',\n",
    "                              #'all_objs_survived_SALT2_DDF' : 'All SALT',\n",
    "                              #'all_objs_survived_SALT2_WFD': 'All SALT',\n",
    "                              #'50SNIa50SNII': 'SN-II 50',\n",
    "                              #'68SNIa32SNII': 'SN-II 32',\n",
    "                              '72SNIa28SNII': 'SN-II 28',\n",
    "                              '75SNIa25SNII': 'SN-II 25', \n",
    "                              '90SNIa10SNII': 'SN-II 10',\n",
    "                              '95SNIa5SNII': 'SN-II 5',\n",
    "                              '98SNIa2SNII': 'SN-II 2',\n",
    "                              '99SNIa1SNII': 'SN-II 1',\n",
    "                              #'50SNIa50SNIbc': 'SN-Ibc 50',\n",
    "                              #'68SNIa32SNIbc': 'SN-Ibc 32',\n",
    "                              #'75SNIa25SNIbc': 'SN-Ibc 25',\n",
    "                              #'83SNIa17SNIbc': 'SN-Ibc 17',\n",
    "                              '90SNIa10SNIbc': 'SN-Ibc 10',\n",
    "                              '95SNIa5SNIbc': 'SN-Ibc 5',\n",
    "                              '98SNIa2SNIbc': 'SN-Ibc 2',\n",
    "                              '99SNIa1SNIbc': 'SN-Ibc 1',\n",
    "                              #'50SNIa50SNIax': 'SN-Iax 50',\n",
    "                              #'68SNIa32SNIax': 'SN-Iax 32',\n",
    "                              '75SNIa25SNIax': 'SN-Iax 25',\n",
    "                              #'86SNIa14SNIax': 'SN-Iax 14',\n",
    "                              '90SNIa10SNIax': 'SN-Iax 10',\n",
    "                              #'94SNIa6SNIax': 'SN-Iax 6',\n",
    "                              '95SNIa5SNIax': 'SN-Iax 5',\n",
    "                              #'97SNIa3SNIax': 'SN-Iax 3',\n",
    "                              '98SNIa2SNIax': 'SN-Iax 2',\n",
    "                              '99SNIa1SNIax': 'SN-Iax 1',\n",
    "                              #'71SNIa29SNIa-91bg': 'SN-Ia-91bg 29',\n",
    "                              #'75SNIa25SNIa-91bg': 'SN-Ia-91bg 25',\n",
    "                              #'90SNIa10SNIa-91bg': 'SN-Ia-91bg 10',\n",
    "                              '95SNIa5SNIa-91bg': 'SN-Ia-91bg 5',\n",
    "                              '98SNIa2SNIa-91bg': 'SN-Ia-91bg 2',\n",
    "                              '99SNIa1SNIa-91bg': 'SN-Ia-91bg 1',\n",
    "                              #'99.8SNIa0.2SNIa-91bg': 'SN-Ia-91bg 0.2',\n",
    "                              #'57SNIa43AGN': 'AGN 43',\n",
    "                              #'75SNIa25AGN': 'AGN 25',\n",
    "                              #'90SNIa10AGN': 'AGN 10',\n",
    "                              #'94SNIa6AGN': 'AGN 6',\n",
    "                              #'95SNIa5AGN': 'AGN 5',\n",
    "                              '98SNIa2AGN': 'AGN 2',\n",
    "                              '99SNIa1AGN': 'AGN 1',\n",
    "                              #'99.9SNIa0.1AGN': 'AGN 0.1',\n",
    "                              #'83SNIa17SLSN-I': 'SLSN-I 17',\n",
    "                              #'90SNIa10SLSN-I': 'SLSN-I 10',\n",
    "                              #'95SNIa5SLSN-I': 'SLSN-I 5',\n",
    "                              #'98SNIa2SLSN-I': 'SLSN-I 2',\n",
    "                              #'99SNIa1SLSN-I': 'SLSN-I 1',\n",
    "                              #'99SNIa1SLSN': 'SLSN 1',\n",
    "                              #'99.9SNIa0.1SLSN': 'SLSN-I 0.1',\n",
    "                              #'95SNIa5TDE': 'TDE 5',\n",
    "                              #'98SNIa2TDE': 'TDE 2',\n",
    "                              #'99SNIa1TDE': 'TDE 1',\n",
    "                              #'99.6SNIa0.4TDE': 'TDE 0.4',\n",
    "                              '99SNIa1CART': 'CART 1'\n",
    "                              #'99.1SNIa0.9CART': 'CART 0.9',\n",
    "                              #'99.7SNIa0.3CART': 'CART 0.3'\n",
    "                  })\n",
    "    else:\n",
    "        remap_dict = OrderedDict({\n",
    "                          'perfect3000': 'Perfect', \n",
    "                          'fiducial3000': 'Fiducial', \n",
    "                          'random3000': 'Random',\n",
    "                          #'all_objs_survived_SALT2_DDF' : 'All SALT',\n",
    "                          #'all_objs_survived_SALT2_WFD': 'All SALT',\n",
    "                          #'50SNIa50SNII': 'SN-II 50',\n",
    "                          #'68SNIa32SNII': 'SN-II 32',\n",
    "                          '72SNIa28SNII': 'SN-II 28',\n",
    "                          '75SNIa25SNII': 'SN-II 25', \n",
    "                          '90SNIa10SNII': 'SN-II 10',\n",
    "                          '95SNIa5SNII': 'SN-II 5',\n",
    "                          '98SNIa2SNII': 'SN-II 2',\n",
    "                          '99SNIa1SNII': 'SN-II 1',\n",
    "                          #'50SNIa50SNIbc': 'SN-Ibc 50',\n",
    "                          #'68SNIa32SNIbc': 'SN-Ibc 32',\n",
    "                          #'75SNIa25SNIbc': 'SN-Ibc 25',\n",
    "                          #'83SNIa17SNIbc': 'SN-Ibc 17',\n",
    "                          #'90SNIa10SNIbc': 'SN-Ibc 10',\n",
    "                          #'92SNIa8SNIbc': 'SN-Ibc 8',\n",
    "                          '95SNIa5SNIbc': 'SN-Ibc 5',\n",
    "                          '98SNIa2SNIbc': 'SN-Ibc 2',\n",
    "                          '99SNIa1SNIbc': 'SN-Ibc 1',\n",
    "                          #'50SNIa50SNIax': 'SN-Iax 50',\n",
    "                          #'68SNIa32SNIax': 'SN-Iax 32',\n",
    "                          #'75SNIa25SNIax': 'SN-Iax 25',\n",
    "                          #'86SNIa14SNIax': 'SN-Iax 14',\n",
    "                          '90SNIa10SNIax': 'SN-Iax 10',\n",
    "                          #'91SNIa9SNIax': 'SN-Iax 9',\n",
    "                          #'94SNIa6SNIax': 'SN-Iax 6',\n",
    "                          '95SNIa5SNIax': 'SN-Iax 5',\n",
    "                          #'97SNIa3SNIax': 'SN-Iax 3',\n",
    "                          '98SNIa2SNIax': 'SN-Iax 2',\n",
    "                          '99SNIa1SNIax': 'SN-Iax 1',\n",
    "                          #'99.1SNIa0.9CART': 'CART 0.9',\n",
    "                           '99.4SNIa0.6CART': 'CART 0.6',\n",
    "                          #'99.7SNIa0.3CART': 'CART 0.3',\n",
    "                          #'71SNIa29SNIa-91bg': 'SN-Ia-91bg 29',\n",
    "                          #'75SNIa25SNIa-91bg': 'SN-Ia-91bg 25',\n",
    "                          #'90SNIa10SNIa-91bg': 'SN-Ia-91bg 10',\n",
    "                          #'95SNIa5SNIa-91bg': 'SN-Ia-91bg 5',\n",
    "                          #'98SNIa2SNIa-91bg': 'SN-Ia-91bg 2',\n",
    "                          #'99SNIa1SNIa-91bg': 'SN-Ia-91bg 1',\n",
    "                          #'99.8SNIa0.2SNIa-91bg': 'SN-Ia-91bg 0.2',\n",
    "                          #'57SNIa43AGN': 'AGN 43',\n",
    "                          #'75SNIa25AGN': 'AGN 25',\n",
    "                          #'90SNIa10AGN': 'AGN 10',\n",
    "                          #'94SNIa6AGN': 'AGN 6',\n",
    "                          #'95SNIa5AGN': 'AGN 5',\n",
    "                          #'98SNIa2AGN': 'AGN 2',\n",
    "                          #'99SNIa1AGN': 'AGN 1',\n",
    "                          #'99.9SNIa0.1AGN': 'AGN 0.1',\n",
    "                          #'83SNIa17SLSN-I': 'SLSN-I 17',\n",
    "                          #'90SNIa10SLSN-I': 'SLSN-I 10',\n",
    "                          #'95SNIa5SLSN-I': 'SLSN-I 5',\n",
    "                          #'98SNIa2SLSN-I': 'SLSN-I 2',\n",
    "                          #'99SNIa1SLSN-I': 'SLSN-I 1',\n",
    "                          #'99SNIa1SLSN': 'SLSN 1',\n",
    "                          '99.9SNIa0.1SLSN': 'SLSN 0.1',\n",
    "                          #'95SNIa5TDE': 'TDE 5',\n",
    "                          #'98SNIa2TDE': 'TDE 2',\n",
    "                          #'99SNIa1TDE': 'TDE 1',\n",
    "                          #'99.6SNIa0.4TDE': 'TDE 0.4',\n",
    "              })\n",
    "    return(remap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remap_dicts = {}\n",
    "for file_extension in file_extensions:\n",
    "    thing = make_remap_dict(file_extensions[file_extension])\n",
    "    tempdict = {}\n",
    "    for case in cases[file_extension]:\n",
    "        if case[:-4] in thing.keys():\n",
    "            tempdict[case[:-4]] = thing[case[:-4]]\n",
    "        #else:\n",
    "            #print(case)\n",
    "    remap_dicts[file_extension] = tempdict#{thing[case[:-4]] for case in cases[file_extension]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the percent contaminated to the colormap.\n",
    "## size corresponds to remap_dict\n",
    "def make_color_nums(file_extension):\n",
    "    if 'wfd' in file_extension:\n",
    "        color_num = np.array([1, 1, 1, #1, 1, 1,                    # Special\n",
    "                           #50, 32, \n",
    "                              28, 25, 10, 5, 2, 1,   # II\n",
    "                           #50, 32, 25, 17, \n",
    "                              10, 5, 2, 1,               # Ibc\n",
    "                           #50, 32, \n",
    "                              25, 10, 5, 2, 1,         # Iax\n",
    "                           #29, 25, 10, \n",
    "                              5, 2, 1,                           # 91bg\n",
    "                           #43, 25, 10, 6, 5, \n",
    "                              2, 1,                       # AGN\n",
    "                           #17, 10, 5, 2, 1, 1, 1,                            # SLSN\n",
    "                           #5, 2, 1, 1,                            # TDE\n",
    "                           1                           # CART\n",
    "                          ]) #+ 1                    \n",
    "    else:\n",
    "        color_num = np.array([1, 1, 1, #1, 1, 1,                    # Special\n",
    "                           #50, 32, \n",
    "                              28, 25, 10, 5, 2, 1,   # II\n",
    "                           #50, 32, 25, 17, 10, 8, \n",
    "                              5, 2, 1,               # Ibc\n",
    "                           #50, 32, 25, 14, \n",
    "                              10, 5, 2, 1,         # Iax\n",
    "                           #1, \n",
    "                              1,                           # CART\n",
    "                           #29, 25, 10, 5, 2, 1, 1,                          # 91bg\n",
    "                           #43, 25, 10, 6, 5, 2, 1, 1,                      # AGN\n",
    "                           #17, 10, 5, 2, 1, 1, \n",
    "                              1                            # SLSN\n",
    "                           #5, 2, 1, 1,                            # TDE\n",
    "                          ]) #+ 1   \n",
    "    return(color_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_nums = {}\n",
    "for file_extension in file_extensions:\n",
    "    color_nums[file_extension] = make_color_nums(file_extensions[file_extension])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color map\n",
    "rainbow = cm = plt.get_cmap('plasma_r')\n",
    "cNorm  = colors.LogNorm(vmin=1, vmax=52) #colors.Normalize(vmin=0, vmax=50)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=rainbow)\n",
    "color_map = scalarMap.to_rgba(np.arange(1, 52))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the curve(s)\n",
    "\n",
    "KDE for each set of posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 2. * sys.float_info.min\n",
    "\n",
    "def safe_log(arr, threshold=eps):\n",
    "    \"\"\"\n",
    "    Takes the natural logarithm of an array that might contain zeros.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr: ndarray, float\n",
    "        array of values to be logged\n",
    "    threshold: float, optional\n",
    "        small, positive value to replace zeros and negative numbers\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logged: ndarray\n",
    "        logged values, with small value replacing un-loggable values\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    arr[arr < threshold] = threshold\n",
    "    logged = np.log(arr)\n",
    "    return logged\n",
    "\n",
    "def make_grid(x, y, x_ngrid=100, y_ngrid=100):\n",
    "    x_min = x.min()#-1.2\n",
    "    x_max = x.max()#-0.8\n",
    "    y_min = y.min()#0.2\n",
    "    y_max = y.max()#0.4\n",
    "\n",
    "    x_grid, y_grid = np.mgrid[x_min:x_max:x_ngrid*1.j, y_min:y_max:y_ngrid*1.j]\n",
    "    x_vec, y_vec = x_grid[:, 0], y_grid[0, :]\n",
    "    dx = (x_max - x_min) / (x_ngrid - 1)\n",
    "    dy = (y_max - y_min) / (y_ngrid - 1)\n",
    "\n",
    "    return(((x_min, y_min), (x_max, y_max)), (x_grid, y_grid), (x_vec, y_vec), (dx, dy))\n",
    "\n",
    "def make_kde(Xgrid, Ygrid, Xsamps, Ysamps, to_log=False, save=None, one_d=True):\n",
    "    if not one_d:\n",
    "        positions = np.vstack([Xgrid.ravel(), Ygrid.ravel()])\n",
    "        values = np.vstack([Xsamps, Ysamps])\n",
    "        kernel = sps.gaussian_kde(values, bw_method='scott')\n",
    "        Z = np.reshape(kernel(positions).T, Xgrid.shape)\n",
    "    else:\n",
    "        positions = Xgrid.T[0]\n",
    "        values = Xsamps\n",
    "        kernel = sps.gaussian_kde(values, bw_method='scott')\n",
    "        Z = kernel(positions)\n",
    "    \n",
    "    if to_log:\n",
    "        return safe_log(Z)\n",
    "    else:\n",
    "        return Z\n",
    "#     if save is not None:\n",
    "# TODO: normalize up here before log!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# alloutputs = pd.DataFrame(columns=['path', 'KLD'])\n",
    "#     # make reference sample\n",
    "# with gzip.open(fullpath+refname) as reffn:\n",
    "#     flatref = pd.read_csv(reffn)\n",
    "# [w_ref, Omm_ref] = [flatref['w'], flatref['om']]\n",
    "# ref_extrema, ref_grids, ref_vecs, ref_ds = make_grid(w_ref, Omm_ref)\n",
    "# (w_vec, Omm_vec) = ref_vecs\n",
    "# (dw, dOmm) = ref_ds\n",
    "# ((xmin, ymin), (xmax, ymax)) = ref_extrema\n",
    "# (w_grid, Omm_grid) = ref_grids\n",
    "# d_ref = {'w': dw, 'Omm': dOmm}\n",
    "# grid_ref = {'w': w_grid, 'Omm': Omm_grid}\n",
    "# kde_ref = make_kde(w_grid, Omm_grid, w_ref, Omm_ref, one_d=True, to_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posteriors(field, k, casename, nsn, withlowz=True):\n",
    "    \n",
    "    if 'perfect' in casename or 'random' in casename or 'fiducial' in casename:\n",
    "        if str(nsn) not in casename:\n",
    "            case = casename + str(nsn)\n",
    "        else:\n",
    "            case = casename\n",
    "    else:\n",
    "        case = casename\n",
    "\n",
    "    filename = 'chains_'+case\n",
    "\n",
    "    if withlowz:\n",
    "        filename = filename+'_lowz_withbias'\n",
    "    path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data3/' + file_extensions[field] + \\\n",
    "               '/results/v' + str(k) + '/' + str(nsn) + '/posteriors/pkl/'\n",
    "#     if field == 'ddf':\n",
    "# #         if k == '':\n",
    "# #             k = 0\n",
    "#         path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/DDF/v'+str(k)+'/posteriors/pkl/'\n",
    "# #             path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/ddf/posteriors/samples_emille/'\n",
    "# #             ext = '.csv.gz'\n",
    "# #         else:\n",
    "# #             path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/ddf/emille_samples'+str(k)+'/posteriors/'\n",
    "    ext = '.pkl'\n",
    "#     elif field == 'wfd':\n",
    "#         path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/wfd/posteriors/samples_emille'+str(k)+'/'\n",
    "#         ext = '.csv.gz'\n",
    "    samppathname = path_pre+filename+ext\n",
    "\n",
    "    if ext == '.csv.gz':\n",
    "        with gzip.open(samppathname) as sampfile:\n",
    "            sampdata = pd.read_csv(sampfile)\n",
    "    elif ext == '.pkl':\n",
    "        with open(samppathname, 'rb') as sampfile:\n",
    "            sampdata = pkl.load(sampfile)\n",
    "#     print(sampdata)\n",
    "    return([sampdata['w'], sampdata['om']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cases = ['perfect', 'random', 'fiducial']\n",
    "ktot = 1\n",
    "kmin = 0\n",
    "samp_sizes = [1500, 3000, 6000]\n",
    "ngrid = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdata = {}\n",
    "for field in file_extensions:\n",
    "    outdata[field] = {}\n",
    "    for casename in null_cases:\n",
    "        outdata[field][casename] = np.empty((ktot, len(samp_sizes), 2, ngrid))\n",
    "        for k in range(kmin, ktot, 1):\n",
    "            for i, nsn in enumerate(samp_sizes):\n",
    "                kpass = k\n",
    "                [w_comp, Omm_comp] = get_posteriors(field, kpass, casename, nsn, withlowz=True)#[sampdata['w'], sampdata['om']]\n",
    "                comp_extrema, comp_grids, comp_vecs, comp_ds = make_grid(w_comp, Omm_comp)\n",
    "                (w_grid, Omm_grid) = comp_grids\n",
    "                kde_comp = make_kde(w_grid, Omm_grid, w_comp, Omm_comp, one_d=True, to_log=True)\n",
    "                outdata[field][casename][k][i] = np.array([w_grid.T[0], kde_comp])\n",
    "with open('default_kdes.pkl', 'wb') as outfile:\n",
    "    pkl.dump(outdata, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdata = {}\n",
    "for field in file_extensions:\n",
    "    outdata[field] = {}\n",
    "    for casename in cases[field]:\n",
    "        outdata[field][casename[:-4]] = np.empty((2, ngrid))\n",
    "        k = '0'\n",
    "        nsn = '3000'\n",
    "        [w_comp, Omm_comp] = get_posteriors(field, k, casename[:-4], nsn, withlowz=True)#[sampdata['w'], sampdata['om']]\n",
    "        comp_extrema, comp_grids, comp_vecs, comp_ds = make_grid(w_comp, Omm_comp)\n",
    "        (w_grid, Omm_grid) = comp_grids\n",
    "        kde_comp = make_kde(w_grid, Omm_grid, w_comp, Omm_comp, one_d=True, to_log=True)\n",
    "        outdata[field][casename[:-4]] = np.array([w_grid.T[0], kde_comp])\n",
    "with open('testcase_kdes.pkl', 'wb') as outfile:\n",
    "    pkl.dump(outdata, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make plot(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_colors = {'perfect': 'k', 'random': 'tab:red', 'fiducial': 'tab:blue'}\n",
    "def_styles = {'1500': ':', '3000': '-', '6000': '--'}#{'DDF': '-', 'WFD': '--'}\n",
    "# def_lowz = {'withbias': , 'nobias':}\n",
    "\n",
    "with open('default_kdes.pkl', 'rb') as infile:\n",
    "    indata = pkl.load(infile)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(6, 7))    \n",
    "for j, field in enumerate(file_extensions):\n",
    "    for casename in null_cases:\n",
    "        ax[j].scatter([0], [0], label=casename, color=def_colors[casename])\n",
    "        for i, nsn in enumerate(samp_sizes):\n",
    "            for k in range(ktot-1, ktot):\n",
    "                w_grid, kde_comp = indata[field][casename][k][i]#[w_grid, kde_comp] = indata[casename]\n",
    "#                 if k == 0:\n",
    "#                     lw_boost = 2\n",
    "# #                     print(kde_comp)\n",
    "#                 else:\n",
    "#                     lw_boost = 1\n",
    "                ax[j].plot(w_grid, np.exp(kde_comp),# label=field+casename, \n",
    "                linestyle=def_styles[str(nsn)], color=def_colors[casename], alpha=0.8, linewidth=1.25)\n",
    "    for nsn in samp_sizes:\n",
    "        ax[j].plot([0], [0], label=str(nsn), \n",
    "                 linestyle=def_styles[str(nsn)], color='tab:green', alpha=1., linewidth=1.25) \n",
    "    ax[j].set_yticks([10, 30, 50])\n",
    "    ax[j].set_yticklabels([10, 30, 50], fontsize=14)\n",
    "    ax[j].set_ylabel(r'PDF ($w^{-1}$)', fontsize=18)\n",
    "    ax[j].vlines(-1., ax[j].get_ylim()[0], ax[j].get_ylim()[1], color='gray', alpha=0.5)\n",
    "    #ax[j].set_ylim(0., 70.)\n",
    "    if j == 0:\n",
    "        yset = ax[j].get_ylim()[1]\n",
    "        ax[j].text(-1.175, 0.85*yset, file_extensions[field], fontsize=20)\n",
    "        ax[j].set_xticks([])\n",
    "    # plt.title(field+k)\n",
    "    if j == 1:\n",
    "        ax[j].set_xticks([-1.2, -1.1, -1.])\n",
    "        ax[j].set_xticklabels([-1.2, -1.1, -1.], fontsize=14)\n",
    "        ax[j].legend(loc='lower left', fontsize=14)#, ncol=2)\n",
    "        ax[j].set_xlabel(r'$w$', fontsize=18)\n",
    "        yset = ax[j].get_ylim()[1]\n",
    "        ax[j].text(-1.175, 0.85*yset, file_extensions[field], fontsize=20)\n",
    "    ax[j].set_xlim(-1.2, -0.95)\n",
    "fig.subplots_adjust(wspace=0., hspace=0.)\n",
    "plt.savefig('dists_null.png', bbox_inches='tight' ,dpi=250)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: investigate the runs that are flat KDEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: also with and without bias of lowz sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates, contaminants = {}, {}\n",
    "for field in file_extensions:\n",
    "    rate, contaminant = {}, {}\n",
    "    for key in remap_dicts[field]:\n",
    "        postsplit = remap_dicts[field][key].split()\n",
    "        if len(postsplit) > 1:\n",
    "            name = postsplit[0]\n",
    "            perc = float(postsplit[-1])\n",
    "#         rate[name] = perc\n",
    "            rate[key] = perc\n",
    "            contaminant[key] = name\n",
    "    rates[field] = rate\n",
    "    contaminants[field] = contaminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for field in file_extensions:\n",
    "#     plt.hist(rates[field].values(), bins=25, alpha=0.5, label=field)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: automate dividing into panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [0., 1., 2., 5., 7.5, 15., 50.]\n",
    "cutofflabels = ['<1%', '1%', '2%', '5%', '10%', '25%']\n",
    "\n",
    "panel_groups = {}\n",
    "for field in file_extensions:\n",
    "    panel_groups[field] = {j: [] for j in range(6)}\n",
    "#     print(field)\n",
    "    for i, casefn in enumerate(rates[field]):\n",
    "        casename = casefn#[:-4]\n",
    "        rate = rates[field][casename]\n",
    "#         for j, cutoff in enumerate(cutoffs[:-1]):\n",
    "#             if rate > cutoffs[j] and rate < :\n",
    "#                 panel_groups[field][0].append(casename)\n",
    "        if rate > 0. and rate < 1.:\n",
    "            panel_groups[field][0].append(casename)\n",
    "#             print((casename, rates[field][casename], 0))\n",
    "        elif rate >= 1. and rate < 2.:\n",
    "            panel_groups[field][1].append(casename)\n",
    "#             print((casename, rates[field][casename], 1))\n",
    "        elif rate >= 2. and rate < 5.:\n",
    "            panel_groups[field][2].append(casename)\n",
    "#             print((casename, rates[field][casename], 1))\n",
    "        elif rate >= 5. and rate < 7.5:\n",
    "            panel_groups[field][3].append(casename)\n",
    "#             print((casename, rates[field][casename], 5))\n",
    "        elif rate >= 7.5 and rate <= 15.:\n",
    "            panel_groups[field][4].append(casename)\n",
    "#             print((casename, rates[field][casename], 10))  \n",
    "        elif rate >= 15. and rate <= 50.:\n",
    "            panel_groups[field][5].append(casename)\n",
    "#             print((casename, rates[field][casename], 25))    \n",
    "#         else:\n",
    "#             print((casename, rates[field][casename], 'big'))\n",
    "print(panel_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_set = set(contaminants['ddf'].values())\n",
    "# if len(file_extensions) > 1:\n",
    "#     for field in file_extensions[1:]:\n",
    "#         base_contaminant_set = set.union(base_contaminant_set, set(contaminants[field].values()))\n",
    "wfd_set = set(contaminants['wfd'].values())\n",
    "all_contaminants = set.union(ddf_set, wfd_set)\n",
    "# base_contaminant_set#\n",
    "\n",
    "color_list = OrderedDict({contaminant: plt.cm.tab10(i) for i, contaminant in enumerate(all_contaminants)})\n",
    "\n",
    "contaminant_colors = {}\n",
    "for field in file_extensions:\n",
    "    contaminant_colors[field] = {}\n",
    "    for i, contaminant in enumerate(contaminants[field]):\n",
    "        contaminant_colors[field][contaminant] = color_list[contaminants[field][contaminant]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_yticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def_colors = {'perfect': 'k', 'random': 'tab:red', 'fiducial': 'tab:blue'}\n",
    "# def_styles = {'1500': ':', '3000': '-', '6000': '--'}#{'DDF': '-', 'WFD': '--'}\n",
    "# def_lowz = {'withbias': , 'nobias':}\n",
    "\n",
    "axs = {}\n",
    "\n",
    "with open('testcase_kdes.pkl', 'rb') as infile:\n",
    "    indata = pkl.load(infile)\n",
    "\n",
    "for field in file_extensions:\n",
    "    table_loc = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/'+file_extensions[field]+'/v'+str(0)+'/summary_stats.csv'\n",
    "#     if field == 'wfd':\n",
    "#         table_loc = '/media2/RESSPECT2/data/posteriors_wfd/omprior_0.01_flat/summary_cases_omprior_0.01_flat_emille.csv'\n",
    "#     else:\n",
    "#         table_loc = '/media2/RESSPECT2/data/posteriors_ddf/omprior_0.01_flat/summary_cases_emille.csv'\n",
    "    df = pd.read_csv(table_loc)\n",
    "    df = df.set_index('case')\n",
    "#     print((field, df.index))\n",
    "    fig = pylab.figure(figsize=(15, 10))\n",
    "    bigAxes = pylab.axes(frameon=False)     # hide frame\n",
    "    bigAxes.set_xticks([])                        # don't want to see any ticks on this axis\n",
    "    bigAxes.set_yticks([])\n",
    "#     bigAxes.set_xlabel(r'$-1.3 < w < -0.9$', fontsize=20)\n",
    "    bigAxes.set_title(file_extensions[field], fontsize=20)\n",
    "    numrows=2\n",
    "    numcols=3\n",
    "#     fig, ax = plt.subplots(2, 3, figsize=(15, 10))\n",
    "#     fig.suptitle(file_extensions[field])\n",
    "    for i in range(len(panel_groups[field])):\n",
    "        per_panel_contaminants = [contaminants[field][panel_groups[field][i][j]] \n",
    "                                  for j in range(len(panel_groups[field][i]))]\n",
    "        uniques, unique_ind = np.unique(per_panel_contaminants, return_index=True)\n",
    "        \n",
    "        axs[i] = fig.add_subplot(numrows,numcols,i+1)\n",
    "        ax = axs[i]\n",
    "#         ax.spines['right'].set_visible(False)\n",
    "#         ax.spines['top'].set_visible(False)\n",
    "#         position = ax.get_position()\n",
    "#         position.x0 += 0.01\n",
    "#         position.y0 += 0.02\n",
    "#         position.x1 += 0.01\n",
    "#         position.y1 += 0.02\n",
    "#         ax.set_position(position)\n",
    "        stylecount = 0\n",
    "        for j, val in enumerate(unique_ind):\n",
    "            casename = panel_groups[field][i][val]\n",
    "            w_grid, kde_comp = indata[field][casename]#[w_grid, kde_comp] = indata[casename]\n",
    "            ax.plot(w_grid, np.exp(kde_comp), color=contaminant_colors[field][casename], label=per_panel_contaminants[val]) \n",
    "#         plt.title(field)\n",
    "#             ax.vlines(df['wfit_w_lowz'].loc[casename], 0, 40, color=contaminant_colors[field][casename], linestyle='--')\n",
    "#             print(df['wfit_w_lowz'].loc[casename])\n",
    "       \n",
    "        l = ax.legend(fontsize=16, loc='upper left', bbox_to_anchor=(-0.025, 1.025), title=cutofflabels[i])#, ncol=2)\n",
    "        plt.setp(l.get_title(),fontsize=14)\n",
    "        ax.set_xlim(-1.25, -0.95)\n",
    "        #ax.text(-1.175, ax.get_ylim()[1]*0.15, cutofflabels[i], fontsize=18, horizontalalignment='right', verticalalignment='center')\n",
    "        if i < 3 and field == 'ddf':\n",
    "            axs[i].set_ylim(0., 30.)\n",
    "            #ax.set_yticklabels([0, 10, 20, 30], fontsize=16)\n",
    "        elif i > 2 and field == 'ddf':\n",
    "            axs[i].set_ylim(0, 45)\n",
    "            \n",
    "        if i < 3 and field == 'wfd':\n",
    "            axs[i].set_ylim(0., 25.)\n",
    "            #ax.set_yticklabels([0, 10, 20, 30], fontsize=16)\n",
    "        elif i > 2 and field == 'wfd':\n",
    "            axs[i].set_ylim(0, 30)\n",
    "            \n",
    "        if i%3 == 0:\n",
    "            ax.set_ylabel(r'PDF ($w^{-1}$)', fontsize=18)\n",
    "            #ax.set_yticks(ax.get_yticks())\n",
    "            #ax.set_yticklabels(ax.get_yticks(), fontsize=16)\n",
    "\n",
    "            #ax.yaxis.set_major_locator(ax.get_yticks(), MaxNLocator(integer=True))\n",
    "        elif i in [1,2]:\n",
    "            ax.set_ylim(axs[0].get_ylim())\n",
    "        elif i in [4,5]:\n",
    "            ax.set_ylim(axs[3].get_ylim())\n",
    "        ax.set_xlabel(r'$w$', fontsize=18)\n",
    "        ax.set_xticks([-1.2, -1.1, -1.])\n",
    "        ax.set_xticklabels([-1.2, -1.1, -1.], fontsize=16)\n",
    "        ax.vlines(-1., ax.get_ylim()[0], ax.get_ylim()[1], color='gray', alpha=0.5)\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "#     lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "#     lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "#     fig.legend(lines, labels)\n",
    "#         ax.set_xticklabels([])\n",
    "#     plt.savefig(file_extensions[field]+'dists_null.png')\n",
    "\n",
    "    for ii in [1,2,4,5]:\n",
    "        axs[ii].set_yticks([])\n",
    "        \n",
    "    axs[0].set_yticks([0, 10, 20, 30])\n",
    "    axs[0].set_yticklabels([0, 10, 20, 30], fontsize=14)\n",
    "\n",
    "    if field == 'ddf':    \n",
    "        axs[3].set_yticks([0, 10, 20, 30,40])\n",
    "        axs[3].set_yticklabels([0, 10, 20, 30,40], fontsize=14)\n",
    "    else:    \n",
    "        axs[3].set_yticks([0, 5, 15, 25])\n",
    "        axs[3].set_yticklabels([0, 5, 15, 25], fontsize=14)\n",
    "    \n",
    "    fig.subplots_adjust(wspace=0., hspace=0.)\n",
    "    pylab.savefig(file_extensions[field]+'combos.png',format='png', bbox_inches='tight', pad_inches=0.3, dpi=250)\n",
    "    #fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: polish these for paper\n",
    "- linestyle for contamination rate if more than one with same contaminant per panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
