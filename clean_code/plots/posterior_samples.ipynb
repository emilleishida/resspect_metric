{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of posterior samples\n",
    "\n",
    "_Kara Ponder (SLAC-->?), Emille Ishida (Clermont-Ferrand), Alex Malz (GCCL@RUB)_\n",
    "\n",
    "plagiarized from `Combination_plots.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import glob\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import scipy.stats as sps\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kara's plotting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# import resspect.cosmo_metric_utils as cmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shapes = {'SNIa-91bg': 'o',\n",
    "              'SNIax': 's',\n",
    "              'SNII': 'd',\n",
    "              'SNIbc': 'X',\n",
    "              'SLSN-I': 'v',\n",
    "              'AGN': '^',\n",
    "              'TDE': '<',\n",
    "              'KN': '>',\n",
    "              'CART': 't'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color map\n",
    "rainbow = cm = plt.get_cmap('plasma_r')\n",
    "cNorm  = colors.LogNorm(vmin=1, vmax=52) #colors.Normalize(vmin=0, vmax=50)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=rainbow)\n",
    "color_map = scalarMap.to_rgba(np.arange(1, 52))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDF summary on the COIN server:\n",
    "file_extensions = {'ddf': 'DDF', \n",
    "                   'wfd': 'WFD'\n",
    "                  }\n",
    "ktot = 3\n",
    "kglob = ''\n",
    "nobjs = '3000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cases(field, k='', nobjs=3000):\n",
    "    if k == '':\n",
    "        k = '0'\n",
    "    dirname = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data3/'+field+'/results/v'+k+'/' + str(nobjs) + '/samples/'\n",
    "    cases = os.listdir(dirname)\n",
    "    \n",
    "    if '.ipynb_checkpoints' in cases:\n",
    "        cases.remove('.ipynb_checkpoints')\n",
    "\n",
    "    return(cases, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases, dirnames = {}, {}\n",
    "for file_extension in file_extensions:\n",
    "    cases[file_extension], dirnames[file_extension] = get_cases(file_extensions[file_extension], k=str(ktot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_remap_dict(file_extension):\n",
    "    if 'wfd' == file_extension:\n",
    "        remap_dict = OrderedDict({\n",
    "                              'perfect3000': 'Perfect', \n",
    "                              'fiducial3000': 'Fiducial', \n",
    "                              'random3000': 'Random',\n",
    "                              '75SNIa25SNII': 'SN-II 25', \n",
    "                              '90SNIa10SNII': 'SN-II 10',\n",
    "                              '95SNIa5SNII': 'SN-II 5',\n",
    "                              '98SNIa2SNII': 'SN-II 2',\n",
    "                              '99SNIa1SNII': 'SN-II 1',\n",
    "                              '90SNIa10SNIbc': 'SN-Ibc 10',\n",
    "                              '95SNIa5SNIbc': 'SN-Ibc 5',\n",
    "                              '98SNIa2SNIbc': 'SN-Ibc 2',\n",
    "                              '99SNIa1SNIbc': 'SN-Ibc 1',\n",
    "                              '75SNIa25SNIax': 'SN-Iax 25',\n",
    "                              '90SNIa10SNIax': 'SN-Iax 10',\n",
    "                              '95SNIa5SNIax': 'SN-Iax 5',\n",
    "                              '98SNIa2SNIax': 'SN-Iax 2',\n",
    "                              '99SNIa1SNIax': 'SN-Iax 1',\n",
    "                              '95SNIa5SNIa-91bg': 'SN-Ia-91bg 5',\n",
    "                              '98SNIa2SNIa-91bg': 'SN-Ia-91bg 2',\n",
    "                              '99SNIa1SNIa-91bg': 'SN-Ia-91bg 1',\n",
    "                              '98SNIa2AGN': 'AGN 2',\n",
    "                              '99SNIa1AGN': 'AGN 1',\n",
    "                              '99SNIa1CART': 'CART 1'\n",
    "                  })\n",
    "    else:\n",
    "        remap_dict = OrderedDict({\n",
    "                          'perfect3000': 'Perfect', \n",
    "                          'fiducial3000': 'Fiducial', \n",
    "                          'random3000': 'Random',\n",
    "                          '72SNIa28SNII': 'SN-II 28',\n",
    "                          '75SNIa25SNII': 'SN-II 25', \n",
    "                          '90SNIa10SNII': 'SN-II 10',\n",
    "                          '95SNIa5SNII': 'SN-II 5',\n",
    "                          '98SNIa2SNII': 'SN-II 2',\n",
    "                          '99SNIa1SNII': 'SN-II 1',\n",
    "                          '95SNIa5SNIbc': 'SN-Ibc 5',\n",
    "                          '98SNIa2SNIbc': 'SN-Ibc 2',\n",
    "                          '99SNIa1SNIbc': 'SN-Ibc 1',\n",
    "                          '90SNIa10SNIax': 'SN-Iax 10',\n",
    "                          '95SNIa5SNIax': 'SN-Iax 5',\n",
    "                          '98SNIa2SNIax': 'SN-Iax 2',\n",
    "                          '99SNIa1SNIax': 'SN-Iax 1',\n",
    "                          '99.4SNIa0.6CART': 'CART 0.6',\n",
    "                          '99.9SNIa0.1SLSN': 'SLSN 0.1'\n",
    "              })\n",
    "    return(remap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remap_dicts = {}\n",
    "for file_extension in file_extensions:\n",
    "    thing = make_remap_dict(file_extension)\n",
    "    tempdict = {}\n",
    "    for case in cases[file_extension]:\n",
    "        if case[:-4] in thing.keys():\n",
    "            tempdict[case[:-4]] = thing[case[:-4]]\n",
    "        #else:\n",
    "            #print(case)\n",
    "    remap_dicts[file_extension] = tempdict#{thing[case[:-4]] for case in cases[file_extension]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the percent contaminated to the colormap.\n",
    "## size corresponds to remap_dict\n",
    "def make_color_nums(file_extension):\n",
    "\n",
    "    if file_extension == 'wfd':\n",
    "        color_num = np.array([1, 1, 1,                     # Special\n",
    "                              28, 25, 10, 5, 2, 1,        # II\n",
    "                              10, 5, 2, 1,                # Ibc\n",
    "                              25, 10, 5, 2, 1,            # Iax\n",
    "                              5, 2, 1,                    # 91bg\n",
    "                              2, 1,                       # AGN\n",
    "                                 1                        # CART\n",
    "                          ])                   \n",
    "    else:\n",
    "        color_num = np.array([1, 1, 1,                  # Special\n",
    "                              25, 10, 5, 2, 1,          # II\n",
    "                              5, 2, 1,                  # Ibc\n",
    "                              10, 5, 2, 1,              # Iax\n",
    "                              1                         # CART\n",
    "                          ]) \n",
    "    return(color_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_nums = {}\n",
    "for file_extension in file_extensions.keys():\n",
    "    color_nums[file_extension] = make_color_nums(file_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color map\n",
    "rainbow = cm = plt.get_cmap('plasma_r')\n",
    "cNorm  = colors.LogNorm(vmin=1, vmax=30) #colors.Normalize(vmin=0, vmax=50)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=rainbow)\n",
    "color_map = scalarMap.to_rgba(np.arange(1, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the curve(s)\n",
    "\n",
    "KDE for each set of posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 2. * sys.float_info.min\n",
    "\n",
    "def safe_log(arr, threshold=eps):\n",
    "    \"\"\"\n",
    "    Takes the natural logarithm of an array that might contain zeros.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr: ndarray, float\n",
    "        array of values to be logged\n",
    "    threshold: float, optional\n",
    "        small, positive value to replace zeros and negative numbers\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logged: ndarray\n",
    "        logged values, with small value replacing un-loggable values\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    arr[arr < threshold] = threshold\n",
    "    logged = np.log(arr)\n",
    "    return logged\n",
    "\n",
    "def make_grid(x, y, x_ngrid=100, y_ngrid=100):\n",
    "    x_min = x.min()#-1.2\n",
    "    x_max = x.max()#-0.8\n",
    "    y_min = y.min()#0.2\n",
    "    y_max = y.max()#0.4\n",
    "\n",
    "    x_grid, y_grid = np.mgrid[x_min:x_max:x_ngrid*1.j, y_min:y_max:y_ngrid*1.j]\n",
    "    x_vec, y_vec = x_grid[:, 0], y_grid[0, :]\n",
    "    dx = (x_max - x_min) / (x_ngrid - 1)\n",
    "    dy = (y_max - y_min) / (y_ngrid - 1)\n",
    "\n",
    "    return(((x_min, y_min), (x_max, y_max)), (x_grid, y_grid), (x_vec, y_vec), (dx, dy))\n",
    "\n",
    "def make_kde(Xgrid, Ygrid, Xsamps, Ysamps, to_log=False, save=None, one_d=True):\n",
    "    if not one_d:\n",
    "        positions = np.vstack([Xgrid.ravel(), Ygrid.ravel()])\n",
    "        values = np.vstack([Xsamps, Ysamps])\n",
    "        kernel = sps.gaussian_kde(values, bw_method='scott')\n",
    "        Z = np.reshape(kernel(positions).T, Xgrid.shape)\n",
    "    else:\n",
    "        positions = Xgrid.T[0]\n",
    "        values = Xsamps\n",
    "        kernel = sps.gaussian_kde(values, bw_method='scott')\n",
    "        Z = kernel(positions)\n",
    "    \n",
    "    if to_log:\n",
    "        return safe_log(Z)\n",
    "    else:\n",
    "        return Z\n",
    "#     if save is not None:\n",
    "# TODO: normalize up here before log!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# alloutputs = pd.DataFrame(columns=['path', 'KLD'])\n",
    "#     # make reference sample\n",
    "# with gzip.open(fullpath+refname) as reffn:\n",
    "#     flatref = pd.read_csv(reffn)\n",
    "# [w_ref, Omm_ref] = [flatref['w'], flatref['om']]\n",
    "# ref_extrema, ref_grids, ref_vecs, ref_ds = make_grid(w_ref, Omm_ref)\n",
    "# (w_vec, Omm_vec) = ref_vecs\n",
    "# (dw, dOmm) = ref_ds\n",
    "# ((xmin, ymin), (xmax, ymax)) = ref_extrema\n",
    "# (w_grid, Omm_grid) = ref_grids\n",
    "# d_ref = {'w': dw, 'Omm': dOmm}\n",
    "# grid_ref = {'w': w_grid, 'Omm': Omm_grid}\n",
    "# kde_ref = make_kde(w_grid, Omm_grid, w_ref, Omm_ref, one_d=True, to_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posteriors(field, k, casename, nsn, withlowz=True):\n",
    "    \n",
    "    if 'perfect' in casename or 'random' in casename or 'fiducial' in casename:\n",
    "        if str(nsn) not in casename:\n",
    "            case = casename + str(nsn)\n",
    "        else:\n",
    "            case = casename\n",
    "    else:\n",
    "        case = casename\n",
    "\n",
    "    filename = 'chains_'+case\n",
    "\n",
    "    if withlowz:\n",
    "        filename = filename+'_lowz_withbias'\n",
    "    path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data3/' + file_extensions[field] + \\\n",
    "               '/results/v' + str(k) + '/' + str(nsn) + '/posteriors/pkl/'\n",
    "#     if field == 'ddf':\n",
    "# #         if k == '':\n",
    "# #             k = 0\n",
    "#         path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/DDF/v'+str(k)+'/posteriors/pkl/'\n",
    "# #             path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/ddf/posteriors/samples_emille/'\n",
    "# #             ext = '.csv.gz'\n",
    "# #         else:\n",
    "# #             path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/ddf/emille_samples'+str(k)+'/posteriors/'\n",
    "    ext = '.pkl'\n",
    "#     elif field == 'wfd':\n",
    "#         path_pre = '/media/RESSPECT/data/PLAsTiCC/for_metrics/wfd/posteriors/samples_emille'+str(k)+'/'\n",
    "#         ext = '.csv.gz'\n",
    "    samppathname = path_pre+filename+ext\n",
    "\n",
    "    if ext == '.csv.gz':\n",
    "        with gzip.open(samppathname) as sampfile:\n",
    "            sampdata = pd.read_csv(sampfile)\n",
    "    elif ext == '.pkl':\n",
    "        with open(samppathname, 'rb') as sampfile:\n",
    "            sampdata = pkl.load(sampfile)\n",
    "#     print(sampdata)\n",
    "    return([sampdata['w'], sampdata['om']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cases = ['perfect', 'random', 'fiducial']\n",
    "ktot = 1\n",
    "kmin = 0\n",
    "samp_sizes = [1500, 3000, 6000]\n",
    "ngrid = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdata = {}\n",
    "for field in file_extensions:\n",
    "    outdata[field] = {}\n",
    "    for casename in null_cases:\n",
    "        outdata[field][casename] = np.empty((ktot, len(samp_sizes), 2, ngrid))\n",
    "        for k in range(kmin, ktot, 1):\n",
    "            for i, nsn in enumerate(samp_sizes):\n",
    "                kpass = k\n",
    "                [w_comp, Omm_comp] = get_posteriors(field, kpass, casename, nsn, withlowz=True)#[sampdata['w'], sampdata['om']]\n",
    "                comp_extrema, comp_grids, comp_vecs, comp_ds = make_grid(w_comp, Omm_comp)\n",
    "                (w_grid, Omm_grid) = comp_grids\n",
    "                kde_comp = make_kde(w_grid, Omm_grid, w_comp, Omm_comp, one_d=True, to_log=True)\n",
    "                outdata[field][casename][k][i] = np.array([w_grid.T[0], kde_comp])\n",
    "with open('default_kdes.pkl', 'wb') as outfile:\n",
    "    pkl.dump(outdata, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdata = {}\n",
    "for field in file_extensions:\n",
    "    outdata[field] = {}\n",
    "    for casename in cases[field]:\n",
    "        outdata[field][casename[:-4]] = np.empty((2, ngrid))\n",
    "        k = '0'\n",
    "        nsn = '3000'\n",
    "        [w_comp, Omm_comp] = get_posteriors(field, k, casename[:-4], nsn, withlowz=True)#[sampdata['w'], sampdata['om']]\n",
    "        comp_extrema, comp_grids, comp_vecs, comp_ds = make_grid(w_comp, Omm_comp)\n",
    "        (w_grid, Omm_grid) = comp_grids\n",
    "        kde_comp = make_kde(w_grid, Omm_grid, w_comp, Omm_comp, one_d=True, to_log=True)\n",
    "        outdata[field][casename[:-4]] = np.array([w_grid.T[0], kde_comp])\n",
    "with open('testcase_kdes.pkl', 'wb') as outfile:\n",
    "    pkl.dump(outdata, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make plot(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_colors = {'perfect': 'k', 'random': 'tab:red', 'fiducial': 'tab:blue'}\n",
    "def_styles = {'1500': ':', '3000': '-', '6000': '--'}#{'DDF': '-', 'WFD': '--'}\n",
    "# def_lowz = {'withbias': , 'nobias':}\n",
    "\n",
    "with open('default_kdes.pkl', 'rb') as infile:\n",
    "    indata = pkl.load(infile)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(6, 7))    \n",
    "for j, field in enumerate(file_extensions):\n",
    "    for casename in null_cases:\n",
    "        ax[j].scatter([0], [0], label=casename, color=def_colors[casename])\n",
    "        for i, nsn in enumerate(samp_sizes):\n",
    "            for k in range(ktot-1, ktot):\n",
    "                w_grid, kde_comp = indata[field][casename][k][i]#[w_grid, kde_comp] = indata[casename]\n",
    "#                 if k == 0:\n",
    "#                     lw_boost = 2\n",
    "# #                     print(kde_comp)\n",
    "#                 else:\n",
    "#                     lw_boost = 1\n",
    "                ax[j].plot(w_grid, np.exp(kde_comp),# label=field+casename, \n",
    "                linestyle=def_styles[str(nsn)], color=def_colors[casename], alpha=0.8, linewidth=1.25)\n",
    "    for nsn in samp_sizes:\n",
    "        ax[j].plot([0], [0], label=str(nsn), \n",
    "                 linestyle=def_styles[str(nsn)], color='tab:green', alpha=1., linewidth=1.25) \n",
    "    ax[j].set_yticks([10, 30, 50])\n",
    "    ax[j].set_yticklabels([10, 30, 50], fontsize=14)\n",
    "    ax[j].set_ylabel(r'PDF ($w^{-1}$)', fontsize=18)\n",
    "    ax[j].vlines(-1., ax[j].get_ylim()[0], ax[j].get_ylim()[1], color='gray', alpha=0.5)\n",
    "    #ax[j].set_ylim(0., 70.)\n",
    "    if j == 0:\n",
    "        yset = ax[j].get_ylim()[1]\n",
    "        ax[j].text(-1.175, 0.85*yset, file_extensions[field], fontsize=20)\n",
    "        ax[j].set_xticks([])\n",
    "    # plt.title(field+k)\n",
    "    if j == 1:\n",
    "        ax[j].set_xticks([-1.2, -1.1, -1.])\n",
    "        ax[j].set_xticklabels([-1.2, -1.1, -1.], fontsize=14)\n",
    "        ax[j].legend(loc='lower left', fontsize=14)#, ncol=2)\n",
    "        ax[j].set_xlabel(r'$w$', fontsize=18)\n",
    "        yset = ax[j].get_ylim()[1]\n",
    "        ax[j].text(-1.175, 0.85*yset, file_extensions[field], fontsize=20)\n",
    "    ax[j].set_xlim(-1.2, -0.95)\n",
    "fig.subplots_adjust(wspace=0., hspace=0.)\n",
    "#plt.savefig('dists_null.pdf', bbox_inches='tight' ,dpi=250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: investigate the runs that are flat KDEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: also with and without bias of lowz sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates, contaminants = {}, {}\n",
    "for field in file_extensions:\n",
    "    rate, contaminant = {}, {}\n",
    "    for key in remap_dicts[field]:\n",
    "        postsplit = remap_dicts[field][key].split()\n",
    "        if len(postsplit) > 1:\n",
    "            name = postsplit[0]\n",
    "            perc = float(postsplit[-1])\n",
    "#         rate[name] = perc\n",
    "            rate[key] = perc\n",
    "            contaminant[key] = name\n",
    "    rates[field] = rate\n",
    "    contaminants[field] = contaminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for field in file_extensions:\n",
    "#     plt.hist(rates[field].values(), bins=25, alpha=0.5, label=field)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: automate dividing into panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [0., 1., 2., 5., 7.5, 15., 50.]\n",
    "cutofflabels = ['<1%', '1%', '2%', '5%', '10%', '25%']\n",
    "\n",
    "panel_groups = {}\n",
    "for field in file_extensions:\n",
    "    panel_groups[field] = {j: [] for j in range(6)}\n",
    "\n",
    "    for i, casefn in enumerate(rates[field]):\n",
    "        casename = casefn#[:-4]\n",
    "        rate = rates[field][casename]\n",
    "        if rate > 0. and rate < 1.:\n",
    "            panel_groups[field][0].append(casename)\n",
    "        elif rate >= 1. and rate < 2.:\n",
    "            panel_groups[field][1].append(casename)\n",
    "        elif rate >= 2. and rate < 5.:\n",
    "            panel_groups[field][2].append(casename)\n",
    "        elif rate >= 5. and rate < 7.5:\n",
    "            panel_groups[field][3].append(casename)\n",
    "        elif rate >= 7.5 and rate <= 15.:\n",
    "            panel_groups[field][4].append(casename)\n",
    "        elif rate >= 15. and rate <= 50.:\n",
    "            panel_groups[field][5].append(casename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_set = set(contaminants['ddf'].values())\n",
    "# if len(file_extensions) > 1:\n",
    "#     for field in file_extensions[1:]:\n",
    "#         base_contaminant_set = set.union(base_contaminant_set, set(contaminants[field].values()))\n",
    "wfd_set = set(contaminants['wfd'].values())\n",
    "all_contaminants = np.unique(np.array(list(ddf_set) + list(wfd_set)))\n",
    "# base_contaminant_set#\n",
    "\n",
    "color_list = OrderedDict({contaminant: plt.cm.tab10(i) for i, contaminant in enumerate(all_contaminants)})\n",
    "\n",
    "contaminant_colors = {}\n",
    "for field in file_extensions:\n",
    "    contaminant_colors[field] = {}\n",
    "    for i, contaminant in enumerate(contaminants[field]):\n",
    "        contaminant_colors[field][contaminant] = color_list[contaminants[field][contaminant]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = {}\n",
    "\n",
    "with open('testcase_kdes.pkl', 'rb') as infile:\n",
    "    indata = pkl.load(infile)\n",
    "\n",
    "for field in file_extensions:\n",
    "    table_loc = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data3/'+file_extensions[field]+'/results/v'+str(3)+'/3000/summary_stats.csv'\n",
    "    \n",
    "    df = pd.read_csv(table_loc)\n",
    "    df = df.set_index('case')\n",
    "\n",
    "    fig = pylab.figure(figsize=(15, 10))\n",
    "    bigAxes = pylab.axes(frameon=False)     # hide frame\n",
    "    bigAxes.set_xticks([])                        # don't want to see any ticks on this axis\n",
    "    bigAxes.set_yticks([])\n",
    "\n",
    "    bigAxes.set_title(file_extensions[field], fontsize=20)\n",
    "    numrows=2\n",
    "    numcols=3\n",
    "\n",
    "    for i in range(len(panel_groups[field])):\n",
    "        per_panel_contaminants = [contaminants[field][panel_groups[field][i][j]] \n",
    "                                  for j in range(len(panel_groups[field][i]))]\n",
    "        uniques, unique_ind = np.unique(per_panel_contaminants, return_index=True)\n",
    "        \n",
    "        axs[i] = fig.add_subplot(numrows,numcols,i+1)\n",
    "        ax = axs[i]\n",
    "\n",
    "        stylecount = 0\n",
    "        for j, val in enumerate(unique_ind):\n",
    "            casename = panel_groups[field][i][val]\n",
    "            w_grid, kde_comp = indata[field][casename]\n",
    "            \n",
    "            if (i > 0):\n",
    "                ax.plot(w_grid, np.exp(kde_comp), color=contaminant_colors[field][casename], label=per_panel_contaminants[val])\n",
    "                \n",
    "            ax.set_xlim(-1.2, -0.9)\n",
    "            ax.set_xlabel(r'$w$', fontsize=18)\n",
    "            ax.set_xticks([-1.15, -1.1, -1.05, -1.0, -0.95])\n",
    "            ax.set_xticklabels([-1.15, -1.1, -1.05,-1.0, -0.95], fontsize=16)\n",
    "                \n",
    "                \n",
    "        if i == 5:    \n",
    "            l = ax.legend(fontsize=13, loc='upper right', bbox_to_anchor=(1.02, 1.02), title=cutofflabels[i])\n",
    "        elif i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            l = ax.legend(fontsize=13, loc='upper left', bbox_to_anchor=(-0.02, 1.02), title=cutofflabels[i])\n",
    "            \n",
    "        plt.setp(l.get_title(),fontsize=14)\n",
    "        \n",
    "        if i < 3 and field == 'ddf':\n",
    "            axs[i].set_ylim(0., 32.)\n",
    "        elif i > 2 and field == 'ddf':\n",
    "            axs[i].set_ylim(0, 45)\n",
    "            \n",
    "        if i < 3 and field == 'wfd':\n",
    "            axs[i].set_ylim(0., 25.)\n",
    "        elif i > 2 and field == 'wfd':\n",
    "            axs[i].set_ylim(0, 30)\n",
    "            \n",
    "        if i%3 == 0:\n",
    "            ax.set_ylabel(r'PDF ($w^{-1}$)', fontsize=18)\n",
    "        elif i in [1,2]:\n",
    "            ax.set_ylim(axs[0].get_ylim())\n",
    "        elif i in [4,5]:\n",
    "            ax.set_ylim(axs[3].get_ylim())\n",
    "        \n",
    "    for ii in [1,2,4,5]:\n",
    "        axs[ii].set_yticks([])\n",
    "        \n",
    "    axs[0].set_yticks([0, 10, 20, 30])\n",
    "    axs[0].set_yticklabels([0, 10, 20, 30], fontsize=14)\n",
    "\n",
    "    if field == 'ddf':    \n",
    "        axs[3].set_yticks([0, 10, 20, 30,40])\n",
    "        axs[3].set_yticklabels([0, 10, 20, 30,40], fontsize=14)\n",
    "    else:    \n",
    "        axs[3].set_yticks([0, 5, 15, 25])\n",
    "        axs[3].set_yticklabels([0, 5, 15, 25], fontsize=14)\n",
    "        \n",
    "    for i in range(6):\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            axs[i].vlines(-1., axs[i].get_ylim()[0], axs[i].get_ylim()[1], color='gray', alpha=0.5)\n",
    "    \n",
    "    \n",
    "    fig.subplots_adjust(wspace=0., hspace=0.)\n",
    "    #pylab.savefig(file_extensions[field]+'combos.png', bbox_inches='tight', pad_inches=0.3, dpi=250)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: polish these for paper\n",
    "- linestyle for contamination rate if more than one with same contaminant per panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "a_file = open(\"colors.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(contaminant_colors, a_file)\n",
    "\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
