{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pylab as plt\n",
    "import progressbar\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate SNANA types\n",
    "types_names = {90:'Ia', 67: '91bg', 52:'Iax', 42:'II', 62:'Ibc', \n",
    "               95: 'SLSN', 15:'TDE', 64:'KN', 88:'AGN', 92:'RRL', 65:'M-dwarf',\n",
    "               16:'EB',53:'Mira', 6:'MicroL', 991:'MicroLB', 992:'ILOT', \n",
    "               993:'CART', 994:'PISN',995:'MLString'}\n",
    "\n",
    "SNANA_types = {90:11, 62:{1:3, 2:13}, 42:{1:2, 2:12, 3:14},\n",
    "               67:41, 52:43, 64:51, 95:60, 994:61, 992:62,\n",
    "               993:63, 15:64, 88:70, 92:80, 65:81, 16:83,\n",
    "               53:84, 991:90, 6:{1:91, 2:93}}\n",
    "\n",
    "SNANA_names = {11: 'Ia', 3:'Ibc', 13: 'Ibc', 2:'II', 12:'II', 14:'II',\n",
    "               41: '91bg', 43:'Iax', 51:'KN', 60:'SLSN', 61:'PISN', 62:'ILOT',\n",
    "               63:'CART', 64:'TDE', 70:'AGN', 80:'RRL', 81:'M-dwarf', 83:'EB',\n",
    "               84:'Mira', 90:'MicroLB', 91:'MicroL', 93:'MicroL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this needs to be run just once\n",
    "output_root = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data3/'\n",
    "\n",
    "for field in ['DDF', 'WFD']:\n",
    "    for version in range(10):\n",
    "        for nobjs in [1500, 3000, 6000]:\n",
    "\n",
    "            # create directory structure\n",
    "            dir_list = [output_root + field + '/',\n",
    "                        output_root + field + '/results/v' + str(version) + '/' + str(nobjs) + '/',\n",
    "                        output_root + field + '/results/v' + str(version) + '/' + str(nobjs) + '/cospar/',\n",
    "                        output_root + field + '/results/v' + str(version) + '/' + str(nobjs) + '/fitres/', \n",
    "                        output_root + field + '/results/v' + str(version) + '/' + str(nobjs) + '/M0DIF/',\n",
    "                        output_root + field + '/results/v' + str(version) + '/' + str(nobjs) + '/posteriors/',\n",
    "                        output_root + field + '/results/v' + str(version) + '/' + str(nobjs) + '/posteriors/csv/',\n",
    "                        output_root + field + '/results/v' + str(version) + '/' + str(nobjs) + '/posteriors/pkl',\n",
    "                        output_root + field + '/results/v' + str(version) + '/' + str(nobjs) + '/posteriors/trace',\n",
    "                        output_root + field + '/results/v' + str(version) + '/' + str(nobjs) + '/samples/',\n",
    "                        output_root + field + '/results/v' + str(version) + '/' + str(nobjs) + '/stan_input/',\n",
    "                        output_root + field + '/results/v' + str(version) +'/' + str(nobjs) +  '/stan_summary/',\n",
    "                      ]\n",
    "\n",
    "            for name in dir_list:\n",
    "                if not os.path.isdir(name):\n",
    "                    os.makedirs(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read zenodo metadata\n",
    "fname = '/media/RESSPECT/data/PLAsTiCC/PLAsTiCC_zenodo/plasticc_test_metadata.csv'\n",
    "test_metadata = pd.read_csv(fname)\n",
    "\n",
    "# separate fields\n",
    "ddf_flag = test_metadata['ddf_bool'].values == 1\n",
    "ids_ddf = test_metadata['object_id'].values[ddf_flag]\n",
    "ids_wfd = test_metadata['object_id'].values[~ddf_flag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create perfect samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = '0'\n",
    "nobjs = 3000\n",
    "data_dir = output_root + field + '/results/v' + v + '/' + str(nobjs) + '/samples/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For DDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all Ias in DDF\n",
    "salt2_Ia_DDF = pd.read_csv(output_root + 'DDF/SALT2_fit/Ia/fitres/master_fitres_1.fitres', \n",
    "                           comment='#', delim_whitespace=True)\n",
    "salt2_Ia_DDF['zHD'] = salt2_Ia_DDF['SIM_ZCMB']          # requirement of so SALT2mu can work\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = -1\n",
    "\n",
    "for i in range(1):\n",
    "    perfect_Ia_DDF = salt2_Ia_DDF.sample(n=nobjs, replace=False)\n",
    "    #perfect_Ia_DDF.to_csv(data_dir + 'DDF/v' + str(i) +  '/samples/perfect' + \\\n",
    "    #                      str(nobjs) + '.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(salt2_Ia_DDF['SIM_TYPE_INDEX'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt2_Ia_DDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(perfect_Ia_DDF['x1'] - perfect_Ia_DDF['SIM_x1'], bins=30)\n",
    "plt.xlabel('x1 - SIM_x1')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(perfect_Ia_DDF['c'] - perfect_Ia_DDF['SIM_c'], bins=20 )\n",
    "plt.xlabel('c - SIM_c')\n",
    "\n",
    "mask = perfect_Ia_DDF['mB'] - perfect_Ia_DDF['SIM_mB'] < 2\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(perfect_Ia_DDF['mB'][mask] - perfect_Ia_DDF['SIM_mB'][mask], bins=20)\n",
    "plt.xlabel('mB - SIM_mB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For WFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all Ias in WFD\n",
    "fnames_Ia = glob.glob(output_root + 'WFD/SALT2_fit/Ia/fitres/master_fitres_*.fitres')\n",
    "\n",
    "salt2_WFD = []\n",
    "\n",
    "for name in fnames_Ia:\n",
    "    try:\n",
    "        fitres_temp = pd.read_csv(name, delim_whitespace=True, \n",
    "                                  comment='#')\n",
    "        fitres_temp['zHD'] = fitres_temp['SIM_ZCMB']\n",
    "        salt2_WFD.append(fitres_temp)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "salt2_Ia_WFD = pd.concat(salt2_WFD, ignore_index=True)\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 1\n",
    "\n",
    "for i in range(v):\n",
    "    perfect_Ia_WFD = salt2_Ia_WFD.sample(n=nobjs, replace=False)\n",
    "    mask = perfect_Ia_WFD['mB'] - perfect_Ia_WFD['SIM_mB'] < 10000\n",
    "    #perfect_Ia_WFD.to_csv(output_root + 'WFD/v' + str(i) + '/samples/perfect' + \\\n",
    "    #                      str(nobjs) + '.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(salt2_Ia_WFD['SIM_TYPE_INDEX'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt2_Ia_WFD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(perfect_Ia_WFD['x1'] - perfect_Ia_WFD['SIM_x1'], bins=30)\n",
    "plt.xlabel('x1 - SIM_x1')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(perfect_Ia_WFD['c'] - perfect_Ia_WFD['SIM_c'], bins=20 )\n",
    "plt.xlabel('c - SIM_c')\n",
    "\n",
    "mask = perfect_Ia_WFD['mB'] - perfect_Ia_WFD['SIM_mB'] < 10000\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(perfect_Ia_WFD['mB'][mask] - perfect_Ia_WFD['SIM_mB'][mask], bins=30)\n",
    "plt.xlabel('mB - SIM_mB')\n",
    "#plt.savefig('dist_WFD_perfct3000.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Random samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For DDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of classes surviving SALT2 fit\n",
    "surv_class_DDF = os.listdir(output_root + 'DDF/SALT2_fit/')\n",
    "\n",
    "# read all SALT2 fit results for DDF\n",
    "all_DDF = []\n",
    "\n",
    "for obj_type in surv_class_DDF: \n",
    "    if obj_type == 'Ia':\n",
    "        data_temp = pd.read_csv(output_root + 'DDF/SALT2_fit/' + \\\n",
    "                            obj_type + '/fitres/master_fitres_1.fitres', \n",
    "                            comment='#', delim_whitespace=True)\n",
    "        data_temp['zHD'] = data_temp['SIM_ZCMB']\n",
    "        data_temp.fillna(-99, inplace=True)\n",
    "        all_DDF.append(data_temp)\n",
    "        print(obj_type, np.unique(data_temp['SIM_TYPE_INDEX'].values), data_temp.shape[0])\n",
    "        \n",
    "    elif obj_type not in ['Ibc', 'II']:\n",
    "        try:\n",
    "            data_temp = pd.read_csv(output_root + 'DDF/SALT2_fit/' + \\\n",
    "                                    obj_type + '/fitres/master_fitres_1.fitres', \n",
    "                                    comment='#', delim_whitespace=True)\n",
    "            data_temp['zHD'] = data_temp['SIM_ZCMB']\n",
    "            data_temp.fillna(-99, inplace=True)\n",
    "            all_DDF.append(data_temp)\n",
    "            print(obj_type, np.unique(data_temp['SIM_TYPE_INDEX'].values), data_temp.shape[0])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    elif obj_type == 'Ibc':\n",
    "        for subtype in ['13', '3']:\n",
    "            data_temp = pd.read_csv(output_root + 'DDF/SALT2_fit/' + \\\n",
    "                                    obj_type + '/fitres/master_fitres_' + subtype \\\n",
    "                                    + '_1.fitres', \n",
    "                                    comment='#', delim_whitespace=True)\n",
    "        \n",
    "            data_temp['zHD'] = data_temp['SIM_ZCMB']\n",
    "            data_temp.fillna(-99, inplace=True)\n",
    "            all_DDF.append(data_temp)\n",
    "            print(obj_type, np.unique(data_temp['SIM_TYPE_INDEX'].values), data_temp.shape[0])\n",
    "    elif obj_type == 'II':\n",
    "        for subtype in ['12', '14', '2']:\n",
    "            data_temp = pd.read_csv(output_root + 'DDF/SALT2_fit/' + \\\n",
    "                                    obj_type + '/fitres/master_fitres_' + subtype \\\n",
    "                                    + '_1.fitres', \n",
    "                                    comment='#', delim_whitespace=True)\n",
    "        \n",
    "            data_temp['zHD'] = data_temp['SIM_ZCMB']\n",
    "            data_temp.fillna(-99, inplace=True)\n",
    "            all_DDF.append(data_temp)\n",
    "            print(obj_type, np.unique(data_temp['SIM_TYPE_INDEX'].values), data_temp.shape[0])\n",
    "    \n",
    "all_surv_DDF = pd.concat(all_DDF, ignore_index=True)\n",
    "all_surv_DDF.fillna(-99, inplace=True)\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 1\n",
    "\n",
    "for i in range(v):\n",
    "    random_DDF = all_surv_DDF.sample(n=nobjs, replace=False)\n",
    "    #random_DDF.to_csv(output_root + 'DDF/results/v' + str(i) + '/' + str(nobjs) + '/samples/random' + \\\n",
    "    #                  str(nobjs) + '.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snana_numbers_ddf, freq_ddf = np.unique(all_surv_DDF['SIM_TYPE_INDEX'].values, \n",
    "                                        return_counts=True)\n",
    "\n",
    "for i in range(len(freq_ddf)):\n",
    "    print(SNANA_names[snana_numbers_ddf[i]], '\\t', freq_ddf[i], \n",
    "          '\\t', 100*freq_ddf[i]/all_surv_DDF.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type II \n",
    "100*(freq_ddf[0] + freq_ddf[3] + freq_ddf[5])/all_surv_DDF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type Ibc\n",
    "100*(freq_ddf[1]+freq_ddf[4])/all_surv_DDF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_surv_DDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For WFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of classes surviving SALT2 fit\n",
    "flist = glob.glob(output_root + 'WFD/SALT2_fit/*/fitres/master_fitres_*.fitres')\n",
    "\n",
    "# read all SALT2 fit results for WFD\n",
    "all_WFD = []\n",
    "for name in flist:\n",
    "    try:\n",
    "        data_temp = pd.read_csv(name, comment='#', delim_whitespace=True)\n",
    "        data_temp['zHD'] = data_temp['SIM_ZCMB']\n",
    "        data_temp.fillna(-99, inplace=True)\n",
    "        all_WFD.append(data_temp)\n",
    "        print(name, np.unique(data_temp['SIM_TYPE_INDEX'].values))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "all_surv_WFD = pd.concat(all_WFD, ignore_index=True)\n",
    "all_surv_WFD.fillna(-99, inplace=True)\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 1\n",
    "\n",
    "for i in range(v):\n",
    "    random_WFD = all_surv_WFD.sample(n=nobjs, replace=False)\n",
    "    #random_WFD.to_csv(output_root + 'WFD/results/v' + str(i) + '/' + str(nobjs) + '/samples/random' + \\\n",
    "    #                  str(nobjs) + '.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt2_Ia_WFD.shape[0]/all_surv_WFD.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snana_numbers_wfd, freq_wfd = np.unique(all_surv_WFD['SIM_TYPE_INDEX'].values, return_counts=True)\n",
    "\n",
    "for i in range(len(freq_wfd)):\n",
    "    print(SNANA_names[snana_numbers_wfd[i]], '\\t', freq_wfd[i], '\\t', 100*freq_wfd[i]/all_surv_WFD.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type II\n",
    "100*(freq_wfd[0]+ freq_wfd[3] + freq_wfd[5])/all_surv_WFD.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type Ibc\n",
    "100*(freq_wfd[1] + freq_wfd[4])/all_surv_WFD.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_surv_WFD.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Fiducial samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For DDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results from avocado\n",
    "fname_DDF = '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/DDF/avocado/avocado_DDF.csv'\n",
    "avocado_DDF = pd.read_csv(fname_DDF, names=['object_id','6','15','16','42','52','53','62','64','65','67','88',\n",
    "                                           '90','92','95'], skiprows=1)\n",
    "\n",
    "# determine final classification\n",
    "class_final_DDF = []\n",
    "for i in progressbar.progressbar(range(avocado_DDF.shape[0])):\n",
    "    indx = np.argsort(avocado_DDF.iloc[i].values[1:])[-1]\n",
    "    code = int(avocado_DDF.keys()[indx + 1])\n",
    "    class_final_DDF.append(types_names[code])\n",
    "class_final_DDF = np.array(class_final_DDF)\n",
    "\n",
    "# get photometrically classified Ia\n",
    "flag_class_Ia_DDF = class_final_DDF == 'Ia'\n",
    "avocado_DDF_Ia = avocado_DDF[flag_class_Ia_DDF]\n",
    "\n",
    "# get SALT2 fit for objs photometrically classified as Ia\n",
    "avocado_DDF_Ia_fitres_flag = np.array([item in avocado_DDF_Ia['object_id'].values \n",
    "                                       for item in all_surv_DDF['CID'].values])\n",
    "all_avocado_DDF_Ia = all_surv_DDF[avocado_DDF_Ia_fitres_flag]\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 10\n",
    "\n",
    "for i in range(v):\n",
    "    fiducial_DDF = all_avocado_DDF_Ia.sample(n=nobjs, replace=False)\n",
    "    fiducial_DDF.to_csv(output_root + 'DDF/results/v' + str(i) + '/' + str(nobjs) + '/samples/fiducial' + \\\n",
    "                      str(nobjs) + '.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_root + 'DDF/results/v' + str(i) + '/' + str(nobjs) + '/samples/fiducial' + \\\n",
    "                      str(nobjs) + '.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For WFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results from avocado\n",
    "fname_WFD =  '/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/WFD/avocado/avocado_WFD.csv'\n",
    "avocado_WFD = pd.read_csv(fname_WFD, names=['object_id','6','15','16','42','52','53','62','64','65','67','88',\n",
    "                                           '90','92','95'], skiprows=1)\n",
    "\n",
    "# determine final classification\n",
    "class_final_WFD = []\n",
    "for i in progressbar.progressbar(range(avocado_WFD.shape[0])):\n",
    "    indx = np.argsort(avocado_WFD.iloc[i].values[1:])[-1]\n",
    "    code = int(avocado_WFD.keys()[indx + 1])\n",
    "    class_final_WFD.append(types_names[code])\n",
    "    \n",
    "# get photometrically classified Ia\n",
    "class_final_WFD = np.array(class_final_WFD)\n",
    "flag_class_Ia_WFD = class_final_WFD == 'Ia'\n",
    "avocado_WFD_Ia = avocado_WFD[flag_class_Ia_WFD]\n",
    "\n",
    "# get SALT2 fit for objs photometrically classified as Ia\n",
    "avocado_WFD_Ia_fitres_flag = np.array([item in avocado_WFD_Ia['object_id'].values \n",
    "                                       for item in all_surv_WFD['CID'].values])\n",
    "all_avocado_WFD_Ia = all_surv_WFD[avocado_WFD_Ia_fitres_flag]\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 10\n",
    "\n",
    "for i in range(v):\n",
    "    fiducial_WFD = all_avocado_WFD_Ia.sample(n=nobjs, replace=False)\n",
    "    fiducial_WFD.to_csv(output_root + 'WFD/results/v' + str(i) + '/' + str(nobjs) + '/samples/fiducial' + \\\n",
    "                      str(nobjs) + '.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj, freq = np.unique(fiducial_WFD['SIM_TYPE_INDEX'].values, return_counts=True)\n",
    "for i in range(len(obj)):\n",
    "    print(SNANA_names[obj[i]], '  --  ', freq[i]/fiducial_WFD.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create single contaminant samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For DDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levels of contamination\n",
    "cont_DDF = {'II': [0.28, 0.25, 0.1, 0.05, 0.02, 0.01],\n",
    "            'Ibc': [0.05, 0.02, 0.01],\n",
    "            'Iax': [0.1, 0.05, 0.02, 0.01],\n",
    "            'CART': [0.006],\n",
    "            'SLSN': [0.001]}\n",
    "\n",
    "complete_names ={'II': 'SNII', 'Ibc': 'SNIbc', 'Iax': 'SNIax', 'CART':'CART',\n",
    "                 '91bg':'SNIa-91bg', 'AGN':'AGN', 'SLSN':'SLSN'}\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 10\n",
    "\n",
    "for i in range(v):\n",
    "    for obj_class in list(cont_DDF.keys()):\n",
    "        # read all contaminants surviving SALT2 fit\n",
    "        if obj_class not in ['II', 'Ibc']:\n",
    "            sample_cont = pd.read_csv(output_root + 'DDF/SALT2_fit/' + obj_class + '/fitres/master_fitres_1.fitres', comment='#',\n",
    "                                  delim_whitespace=True)\n",
    "        elif obj_class == 'Ibc':\n",
    "            sample_cont_list = []\n",
    "            for subset in  ['13', '3']:\n",
    "                data_temp = pd.read_csv(output_root + 'DDF/SALT2_fit/' + \\\n",
    "                                        obj_class + '/fitres/master_fitres_' + subset \\\n",
    "                                        + '_1.fitres', \n",
    "                                        comment='#', delim_whitespace=True)\n",
    "                sample_cont_list.append(data_temp)\n",
    "                \n",
    "            sample_cont = pd.concat(sample_cont_list, ignore_index=True) \n",
    "            \n",
    "        elif obj_class == 'II':\n",
    "            sample_cont_list = []\n",
    "            for subset in ['12', '14', '2']:\n",
    "                data_temp = pd.read_csv(output_root + 'DDF/SALT2_fit/' + \\\n",
    "                                        obj_class + '/fitres/master_fitres_' + subset \\\n",
    "                                        + '_1.fitres', \n",
    "                                        comment='#', delim_whitespace=True)\n",
    "                \n",
    "                sample_cont_list.append(data_temp)\n",
    "                \n",
    "            sample_cont = pd.concat(sample_cont_list, ignore_index=True) \n",
    "        \n",
    "        sample_cont['zHD'] = sample_cont['SIM_ZCMB']\n",
    "    \n",
    "        for perc in cont_DDF[obj_class]:\n",
    "            Ia_temp = salt2_Ia_DDF.sample(n=int((1 - perc) * nobjs), replace=False)\n",
    "            cont_temp = sample_cont.sample(n=int(perc * nobjs), replace = False)\n",
    "            sample_final = pd.concat([Ia_temp, cont_temp], ignore_index=True)\n",
    "            sample_final.fillna(-99, inplace=True)\n",
    "        \n",
    "            #if obj_class not in ['CART', 'SLSN']:\n",
    "            #    sample_final.to_csv(output_root + 'DDF/results/v' + str(i)  + '/' + str(nobjs) + '/samples/' + str(int(100 - 100 * perc)) + \\\n",
    "            #                        'SNIa' + str(int(100 * perc)) + complete_names[obj_class] + '.csv', \n",
    "            #                         sep=' ', index=False)\n",
    "            #else:\n",
    "            #    sample_final.to_csv(output_root + 'DDF/results/v' + str(i) + '/'+  str(nobjs) + '/samples/' + str(round(100 - 100 * perc, 1)) + \\\n",
    "            #                        'SNIa' + str(round(100 * perc, 1)) + complete_names[obj_class] + '.csv', \n",
    "            #                         sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For WFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levels of contamination\n",
    "cont_WFD = {'II': [0.28, 0.25, 0.1, 0.05, 0.02, 0.01],\n",
    "            'Ibc': [0.1, 0.05, 0.02, 0.01],\n",
    "            'Iax': [0.25, 0.1, 0.05, 0.02, 0.01],\n",
    "            'SLSN': [0.15, 0.10, 0.05, 0.02, 0.01],\n",
    "            '91bg': [0.1, 0.05, 0.02, 0.01],\n",
    "            'AGN': [0.04, 0.02, 0.01],\n",
    "            'PISN': [0.003],\n",
    "             'ILOT': [0.006],\n",
    "            'CART': [0.1, 0.05, 0.02, 0.01]}\n",
    "\n",
    "complete_names ={'II': 'SNII', 'Ibc': 'SNIbc', 'Iax': 'SNIax', 'CART':'CART',\n",
    "                 '91bg':'SNIa-91bg', 'AGN':'AGN', 'PISN':'PISN', 'ILOT':'ILOT', 'SLSN':'SLSN'}\n",
    "\n",
    "for i in range(v):\n",
    "    for obj_class in list(cont_WFD.keys()):\n",
    "        # read all contaminants surviving SALT2 fit\n",
    "        flist = glob.glob(output_root + 'WFD/SALT2_fit/' + obj_class + '/fitres/master_fitres_*.fitres')\n",
    "        \n",
    "        sample_cont = []\n",
    "        for name in flist:\n",
    "            \n",
    "            try:\n",
    "                temp_cont = pd.read_csv(name, comment='#', delim_whitespace=True)\n",
    "                temp_cont['zHD'] = temp_cont['SIM_ZCMB']\n",
    "                sample_cont.append(temp_cont)\n",
    "                print(obj_class, perc, '  temp_cont.size = ', temp_cont.shape[0], '  ', \n",
    "                  str(np.unique(temp_cont['SIM_TYPE_INDEX'])) )\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        if len(sample_cont) > 0:\n",
    "            sample_cont2 = pd.concat(sample_cont, ignore_index=True)\n",
    "    \n",
    "            for perc in cont_WFD[obj_class]:                \n",
    "                Ia_temp2 = salt2_Ia_WFD.sample(n=int((1-perc)*nobjs), replace=False)\n",
    "                cont_temp2 = sample_cont2.sample(n=int(perc*nobjs), replace = False)\n",
    "                sample_final = pd.concat([Ia_temp2, cont_temp2], ignore_index=True)\n",
    "                sample_final.fillna(-99, inplace=True)\n",
    "                if obj_class in ['Iax'] :\n",
    "                    sample_final.to_csv(output_root + 'WFD/results/v' + str(i) + '/' + str(nobjs) + '/samples/' + str(int(100 - 100 * perc)) + \\\n",
    "                                       'SNIa' + str(int(100 * perc)) + complete_names[obj_class] + '.csv', \n",
    "                                    sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
