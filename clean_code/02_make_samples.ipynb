{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate SNANA types\n",
    "types_names = {90:'Ia', 67: '91bg', 52:'Iax', 42:'II', 62:'Ibc', \n",
    "               95: 'SLSN', 15:'TDE', 64:'KN', 88:'AGN', 92:'RRL', 65:'M-dwarf',\n",
    "               16:'EB',53:'Mira', 6:'MicroL', 991:'MicroLB', 992:'ILOT', \n",
    "               993:'CART', 994:'PISN',995:'MLString'}\n",
    "\n",
    "SNANA_types = {90:11, 62:{1:3, 2:13}, 42:{1:2, 2:12, 3:14},\n",
    "               67:41, 52:43, 64:51, 95:60, 994:61, 992:62,\n",
    "               993:63, 15:64, 88:70, 92:80, 65:81, 16:83,\n",
    "               53:84, 991:90, 6:{1:91, 2:93}}\n",
    "\n",
    "SNANA_names = {11: 'Ia', 3:'Ibc', 13: 'Ibc', 2:'II', 12:'II', 14:'II',\n",
    "               41: '91bg', 43:'Iax', 51:'KN', 60:'SLSN', 61:'PISN', 62:'ILOT',\n",
    "               63:'CART', 64:'TDE', 70:'AGN', 80:'RRL', 81:'M-dwarf', 83:'EB',\n",
    "               84:'Mira', 90:'MicroLB', 91:'MicroL', 93:'MicroL'}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this needs to be run just once\n",
    "output_root = '/media2/RESSPECT2/clean_output/'\n",
    "\n",
    "for field in ['DDF', 'WFD']:\n",
    "    for version in range(6):\n",
    "\n",
    "        # create directory structure\n",
    "        dir_list = [output_root + field + '/',\n",
    "            output_root + field + '/v' + str(version) + '/',\n",
    "            output_root + field + '/v' + str(version) + '/cospar/',\n",
    "            output_root + field + '/v' + str(version) + '/fitres/', \n",
    "            output_root + field + '/v' + str(version) + '/M0DIF/',\n",
    "            output_root + field + '/v' + str(version) + '/posteriors/',\n",
    "            output_root + field + '/v' + str(version) + '/posteriors/csv/',\n",
    "            output_root + field + '/v' + str(version) + '/posteriors/pkl',\n",
    "            output_root + field + '/v' + str(version) + '/samples/',\n",
    "            output_root + field + '/v' + str(version) + '/stan_input/',\n",
    "            output_root + field + '/v' + str(version) + '/stan_summary/',\n",
    "           ]\n",
    "\n",
    "        for name in dir_list:\n",
    "            if not os.path.isdir(name):\n",
    "                os.makedirs(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read zenodo metadata\n",
    "fname = '/media/RESSPECT/data/PLAsTiCC/PLAsTiCC_zenodo/plasticc_test_metadata.csv'\n",
    "test_metadata = pd.read_csv(fname)\n",
    "\n",
    "# separate fields\n",
    "ddf_flag = test_metadata['ddf_bool'].values == 1\n",
    "ids_ddf = test_metadata['object_id'].values[ddf_flag]\n",
    "ids_wfd = test_metadata['object_id'].values[~ddf_flag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create perfect samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media2/RESSPECT2/clean_output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For DDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all Ias in DDF\n",
    "salt2_Ia_DDF = pd.read_csv('/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/DDF/SALT2_fit/Ia/master_fitres.fitres', comment='#', delim_whitespace=True)\n",
    "salt2_Ia_DDF['zHD'] = salt2_Ia_DDF['SIM_ZCMB']          # requirement of so SALT2mu can work\n",
    "\n",
    "# choose sample size\n",
    "nobjs = 3000\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 6\n",
    "\n",
    "for i in range(v):\n",
    "    perfect_Ia_DDF = salt2_Ia_DDF.sample(n=nobjs, replace=False)\n",
    "    #perfect_Ia_DDF.to_csv(data_dir + 'DDF/v' + str(i) +  '/samples/perfect' + \\\n",
    "    #                      str(nobjs) + '.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For WFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all Ias in WFD\n",
    "fnames_Ia = glob.glob('/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/WFD/SALT2_fit/Ia/master_fitres_*.fitres')\n",
    "\n",
    "salt2_WFD = []\n",
    "\n",
    "for name in fnames_Ia:\n",
    "    fitres_temp = pd.read_csv(name, delim_whitespace=True, \n",
    "                              comment='#')\n",
    "    fitres_temp['zHD'] = fitres_temp['SIM_ZCMB']\n",
    "    salt2_WFD.append(fitres_temp)\n",
    "\n",
    "salt2_Ia_WFD = pd.concat(salt2_WFD, ignore_index=True)\n",
    "\n",
    "# choose sample size\n",
    "nobjs = 3000\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 6\n",
    "\n",
    "for i in range(v):\n",
    "    perfect_Ia_WFD = salt2_Ia_WFD.sample(n=nobjs, replace=False)\n",
    "    #perfect_Ia_WFD.to_csv(data_dir + 'WFD/v' + str(i) + '/samples/perfect' + \\\n",
    "    #                      str(nobjs) + '.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Random samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For DDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of classes surviving SALT2 fit\n",
    "surv_class_DDF = ['91bg', 'AGN', 'CART', 'Ia', 'Iax', 'Ibc', 'II', 'TDE']\n",
    "\n",
    "# read all SALT2 fit results for DDF\n",
    "all_DDF = []\n",
    "for obj_type in surv_class_DDF:\n",
    "    data_temp = pd.read_csv('/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/DDF/SALT2_fit/' + obj_type + '/master_fitres.fitres', \n",
    "                            comment='#', delim_whitespace=True)\n",
    "    data_temp['zHD'] = data_temp['SIM_ZCMB']\n",
    "    data_temp.fillna(-99, inplace=True)\n",
    "    all_DDF.append(data_temp)\n",
    "    \n",
    "all_surv_DDF = pd.concat(all_DDF, ignore_index=True)\n",
    "all_surv_DDF.fillna(-99, inplace=True)\n",
    "\n",
    "# choose sample size\n",
    "nobjs = 3000\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 6\n",
    "\n",
    "for i in range(v):\n",
    "    random_DDF = all_surv_DDF.sample(n=nobjs, replace=False)\n",
    "    #random_DDF.to_csv(data_dir + 'DDF/v' + str(i) + '/samples/random' + \\\n",
    "    #                  str(nobjs) + '.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For WFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of classes surviving SALT2 fit\n",
    "surv_class_WFD = ['91bg', 'AGN', 'CART', 'Ia', 'Iax', 'Ibc', 'II', 'TDE', 'ILOT', 'PISN', 'SLSN']\n",
    "\n",
    "# read all SALT2 fit results for WFD\n",
    "all_WFD = []\n",
    "for obj_type in surv_class_WFD:\n",
    "    flist = glob.glob('/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/WFD/SALT2_fit/' + obj_type + '/master_fitres_*.fitres')\n",
    "    \n",
    "    for name in flist:\n",
    "        data_temp = pd.read_csv(name, comment='#', delim_whitespace=True)\n",
    "        data_temp['zHD'] = data_temp['SIM_ZCMB']\n",
    "        data_temp.fillna(-99, inplace=True)\n",
    "        all_WFD.append(data_temp)\n",
    "        \n",
    "    \n",
    "all_surv_WFD = pd.concat(all_WFD, ignore_index=True)\n",
    "all_surv_WFD.fillna(-99, inplace=True)\n",
    "\n",
    "# choose sample size\n",
    "nobjs = 3000\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 6\n",
    "\n",
    "for i in range(6, v):\n",
    "    random_WFD = all_surv_WFD.sample(n=nobjs, replace=False)\n",
    "    #random_WFD.to_csv(data_dir + 'WFD/v' + str(i) + '/samples/perfect' + \\\n",
    "    #                  str(nobjs) + '.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Fiducial samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For DDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results from avocado\n",
    "fname_DDF = data_dir + 'DDF/avocado/avocado_DDF.csv'\n",
    "avocado_DDF = pd.read_csv(fname_DDF, names=['object_id','6','15','16','42','52','53','62','64','65','67','88',\n",
    "                                           '90','92','95'], skiprows=1)\n",
    "\n",
    "# determine final classification\n",
    "class_final_DDF = []\n",
    "for i in range(avocado_DDF.shape[0]):\n",
    "    indx = np.argsort(avocado_DDF.iloc[i].values[1:])[-1]\n",
    "    code = int(avocado_DDF.keys()[indx + 1])\n",
    "    class_final_DDF.append(types_names[code])\n",
    "class_final_DDF = np.array(class_final_DDF)\n",
    "\n",
    "# get photometrically classified Ia\n",
    "flag_class_Ia_DDF = class_final_DDF == 'Ia'\n",
    "avocado_DDF_Ia = avocado_DDF[flag_class_Ia_DDF]\n",
    "\n",
    "# get SALT2 fit for objs photometrically classified as Ia\n",
    "avocado_DDF_Ia_fitres_flag = np.array([item in avocado_DDF_Ia['object_id'].values for item in all_surv_DDF['CID'].values])\n",
    "all_avocado_DDF_Ia = all_surv_DDF[avocado_DDF_Ia_fitres_flag]\n",
    "\n",
    "# choose sample size\n",
    "nobjs = 6000\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 6\n",
    "\n",
    "for i in range(v):\n",
    "    fiducial_DDF = all_avocado_DDF_Ia.sample(n=nobjs, replace=False)\n",
    "    #fiducial_DDF.to_csv(data_dir + 'DDF/v' + str(i) + '/samples/fiducial' + \\\n",
    "    #                  str(nobjs) + '.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For WFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results from avocado\n",
    "fname_WFD =  data_dir + 'WFD/avocado/avocado_WFD.csv'\n",
    "avocado_WFD = pd.read_csv(fname_WFD, names=['object_id','6','15','16','42','52','53','62','64','65','67','88',\n",
    "                                           '90','92','95'], skiprows=1)\n",
    "\n",
    "# determine final classification\n",
    "class_final_WFD = []\n",
    "for i in range(avocado_WFD.shape[0]):\n",
    "    indx = np.argsort(avocado_WFD.iloc[i].values[1:])[-1]\n",
    "    code = int(avocado_WFD.keys()[indx + 1])\n",
    "    class_final_WFD.append(types_names[code])\n",
    "    \n",
    "# get photometrically classified Ia\n",
    "class_final_WFD = np.array(class_final_WFD)\n",
    "flag_class_Ia_WFD = class_final_WFD == 'Ia'\n",
    "avocado_WFD_Ia = avocado_WFD[flag_class_Ia_WFD]\n",
    "\n",
    "# get SALT2 fit for objs photometrically classified as Ia\n",
    "avocado_WFD_Ia_fitres_flag = np.array([item in avocado_WFD_Ia['object_id'].values \n",
    "                                       for item in all_surv_WFD['CID'].values])\n",
    "all_avocado_WFD_Ia = all_surv_WFD[avocado_WFD_Ia_fitres_flag]\n",
    "\n",
    "# choose sample size\n",
    "nobjs = 3000\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 7\n",
    "\n",
    "for i in range(6, v):\n",
    "    fiducial_WFD = all_avocado_WFD_Ia.sample(n=nobjs, replace=False)\n",
    "    #fiducial_WFD.to_csv(data_dir + 'WFD/v' + str(i) + '/samples/perfect' + \\\n",
    "    #                  str(nobjs) + '.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create single contaminant samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For DDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levels of contamination\n",
    "cont_DDF = {'II': [0.28, 0.25, 0.1, 0.05, 0.02, 0.01],\n",
    "            'Ibc': [0.05, 0.02, 0.01],\n",
    "            'Iax': [0.14, 0.1, 0.05, 0.02, 0.01],\n",
    "            'CART': [0.009], \n",
    "            '91bg': [0.002],\n",
    "            'AGN': [0.001]}\n",
    "\n",
    "complete_names ={'II': 'SNII', 'Ibc': 'SNIbc', 'Iax': 'SNIax', 'CART':'CART',\n",
    "                 '91bg':'SNIa-91bg', 'AGN':'AGN'}\n",
    "\n",
    "# choose sample size\n",
    "nobjs = 3000\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 6\n",
    "\n",
    "for i in range(v):\n",
    "    for obj_class in list(cont_DDF.keys()):\n",
    "        # read all contaminants surviving SALT2 fit\n",
    "        sample_cont = pd.read_csv('/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/DDF/SALT2_fit/' + obj_class + '/master_fitres.fitres', comment='#',\n",
    "                              delim_whitespace=True)\n",
    "        sample_cont['zHD'] = sample_cont['SIM_ZCMB']\n",
    "    \n",
    "        for perc in cont_DDF[obj_class]:\n",
    "            Ia_temp = salt2_Ia_DDF.sample(n=int((1 - perc) * nobjs), replace=False)\n",
    "            cont_temp = sample_cont.sample(n=int(perc * nobjs), replace = False)\n",
    "            sample_final = pd.concat([Ia_temp, cont_temp], ignore_index=True)\n",
    "            sample_final.fillna(-99, inplace=True)\n",
    "        \n",
    "            if obj_class not in ['CART', '91bg', 'AGN']:\n",
    "                sample_final.to_csv(data_dir + 'DDF/v' + str(i) + '/samples/' + str(int(100 - 100 * perc)) + \\\n",
    "                                    'SNIa' + str(int(100 * perc)) + complete_names[obj_class] + '.csv', \n",
    "                                     sep=' ', index=False)\n",
    "            else:\n",
    "                sample_final.to_csv(data_dir + 'DDF/v' + str(i) + '/samples/' + str(round(100 - 100 * perc, 1)) + \\\n",
    "                                    'SNIa' + str(round(100 * perc, 1)) + complete_names[obj_class] + '.csv', \n",
    "                                     sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For WFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levels of contamination\n",
    "cont_WFD = {'II': [0.28, 0.25, 0.1, 0.05, 0.02, 0.01],\n",
    "            'Ibc': [0.1, 0.05, 0.02, 0.01],\n",
    "            'Iax': [0.25, 0.1, 0.05, 0.02, 0.01],\n",
    "            '91bg': [0.05, 0.02, 0.01],\n",
    "            'AGN': [0.05, 0.02, 0.01],\n",
    "            'TDE': [0.004],\n",
    "            'CART': [0.003]}\n",
    "\n",
    "complete_names ={'II': 'SNII', 'Ibc': 'SNIbc', 'Iax': 'SNIax', 'CART':'CART',\n",
    "                 '91bg':'SNIa-91bg', 'AGN':'AGN', 'TDE':'TDE'}\n",
    "\n",
    "# choose sample size\n",
    "nobjs = 3000\n",
    "\n",
    "# choose number of versions of the same sample to generate\n",
    "v = 6\n",
    "\n",
    "for i in range(v):\n",
    "    for obj_class in list(cont_WFD.keys()):\n",
    "        # read all contaminants surviving SALT2 fit\n",
    "        flist = glob.glob('/media/RESSPECT/data/PLAsTiCC/for_metrics/final_data/WFD/SALT2_fit/' + obj_class + '/master_fitres_*.fitres')\n",
    "        \n",
    "        sample_cont = []\n",
    "        for name in flist:\n",
    "            temp_cont = pd.read_csv(name, comment='#', delim_whitespace=True)\n",
    "            temp_cont['zHD'] = temp_cont['SIM_ZCMB']\n",
    "            sample_cont.append(temp_cont)\n",
    "            \n",
    "        sample_cont2 = pd.concat(sample_cont, ignore_index=True)\n",
    "    \n",
    "        for perc in cont_WFD[obj_class]:\n",
    "            Ia_temp2 = salt2_Ia_WFD.sample(n=int((1-perc)*nobjs), replace=False)\n",
    "            cont_temp2 = sample_cont2.sample(n=int(perc*nobjs), replace = False)\n",
    "            sample_final = pd.concat([Ia_temp2, cont_temp2], ignore_index=True)\n",
    "            sample_final.fillna(-99, inplace=True)\n",
    "        \n",
    "            #sample_final.to_csv(data_dir + 'WFD/v' + str(i) + '/samples/' + str(int(100 - 100 * perc)) + \\\n",
    "            #              'SNIa' + str(int(100 * perc)) + complete_names[obj_class] + '.csv', \n",
    "            #              sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
