{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulating realistically bad-for-cosmology SN Ia samples from PLAsTiCC data\n",
    "\n",
    "_Alex I. Malz (GCCL@RUB)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "rando = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proclam\n",
    "from proclam.metrics.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classes we care about\n",
    "\n",
    "| `true_target`=`type` | `code` |\n",
    "| -------------------- | ------ |\n",
    "| 90 | SNIa |\n",
    "| 67 | SNIa-91bg |\n",
    "| 52 | SNIax |\n",
    "| 42 | SNII |\n",
    "| 62 | SNIbc |\n",
    "| 95 | SLSN-I |\n",
    "| 88 | AGN |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe_sn_classes = {90: 'SNIa', \n",
    "                    67: 'SNIa-91bg', \n",
    "                    52: 'SNIax', \n",
    "                    42: 'SNII', \n",
    "                    62: 'SNIbc', \n",
    "                    95: 'SLSN-I', \n",
    "                    88: 'AGN'}\n",
    "maybe_sn_classes[64] = 'KN'\n",
    "maybe_sn_classes[15] = 'TDE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gather all available lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/media/RESSPECT/data/PLAsTiCC/PLAsTiCC_zenodo/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other than intermediate data products, work in `/media/RESSPECT/data/PLAsTiCC/for_metrics/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_maybe_sn = pd.read_csv('/media/RESSPECT/data/PLAsTiCC/PLAsTiCC_zenodo/plasticc_test_metadata.csv')\n",
    "print(len(all_maybe_sn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_maybe_sn = all_maybe_sn.rename(columns={\"object_id\": \"id\", \"true_z\": \"redshift\", \"true_target\": \"code\"})\n",
    "print(all_maybe_sn.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_maybe_sn['orig_sample'] = 'test'\n",
    "# all_maybe_sn['queryable'] = True\n",
    "# all_maybe_sn['type'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DDF now, WFD later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ddf = all_maybe_sn.loc[all_maybe_sn['ddf_bool'] == 1][['id', 'redshift', 'code']]\n",
    "# true_wfd = all_maybe_sn.loc[all_maybe_sn['ddf_bool'] == 0][['id', 'redshift', 'code']]\n",
    "n_ddf_tot = len(true_ddf)\n",
    "n_ddf_all = dict(true_ddf.groupby('code').count()['id'])\n",
    "# ddf_rats = dict(true_ddf.groupby('code').count()['id'] / n_ddf_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a priori all samples will be 3000 \"classified SN Ia\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subsample the classes to make new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class_pos = 3000\n",
    "sel_class = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### as in proclam, based on a confusion matrix\n",
    "\n",
    "start from fiducial contamination rates from a real (awful) confusion matrix at `/media/RESSPECT/data/PLAsTiCC/for_metrics/confusion_matrices`\n",
    "\n",
    "figure out classes in confusion matrix by comparing number of ddf test set-only lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(savepath+'confusion_matrices/confusion_matrix.npy', 'rb') as confmat:\n",
    "    cm = np.load(confmat)\n",
    "n_cm = np.sum(cm)\n",
    "plt.imshow(np.log(cm), cmap='viridis_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These were just the test set lightcurves for classes (67, 88, 42(minus 7?), 90(minus 11?), 52, 62, 64, 95, 15) from ddf-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_classes = [67, 88, 42, 90, 52, 62, 64, 95, 15]\n",
    "cm_indices = {}\n",
    "# cm_rat = {}\n",
    "for classid in maybe_sn_classes.keys():\n",
    "    cm_indices[classid] = cm_classes.index(classid)\n",
    "#     cm_rat[classid] = sum(cm[cm_indices[classid]]) / n_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get sample ids matching a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original plan was to have these samples:\n",
    "- 100% Ia\n",
    "- Ia/Ibc\n",
    "- - 50/50\n",
    "- - 75/25\n",
    "- - 90/10\n",
    "- - 95/5\n",
    "- - 98/2\n",
    "- Ia/II\n",
    "- Ia/91bg\n",
    "- Ia/Iax\n",
    "- AGN\n",
    "- TDE \n",
    "- KN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = '/media/RESSPECT/data/PLAsTiCC/for_metrics/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save outputs as `id,redshift,type,code,orig_sample=test,queryable=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_samp_ids(cm, cm_indices, samp_key, ntot=n_samp, where_to_save=None, rando=rando):\n",
    "    cm_row = cm.T[cm_indices[samp_key]]\n",
    "    out_ids = pd.DataFrame(columns=all_maybe_sn.columns)\n",
    "    for typeid in cm_indices.keys():\n",
    "        if not ntot:\n",
    "            n_to_sample = int(cm_row[cm_indices[typeid]])\n",
    "        matches = all_maybe_sn[all_maybe_sn['code'] == typeid].sample(n=n_to_sample, random_state=rando)\n",
    "        if len(matches) > 0:\n",
    "            out_ids = out_ids.append(matches)\n",
    "    out_ids['orig_sample'] = 'test'\n",
    "    out_ids['queryable'] = True\n",
    "    out_ids['type'] = None\n",
    "    if where_to_save:\n",
    "        out_ids[['id','redshift','type','code','orig_sample','queryable']].to_csv(where_to_save+'.csv', index=False)\n",
    "    return(out_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100% SNIa sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_perfect = np.diag(cm) * np.identity(len(cm_indices.keys()))\n",
    "perfect = gen_samp_ids(cm_perfect, cm_indices, sel_class)#, where_to_save=savepath+'perfect_samp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"realistic\" sample\n",
    "\n",
    "fiducial sample corresponding to input confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiducial = gen_samp_ids(cm, cm_indices, sel_class)#, where_to_save=savepath+'fiducial_samp')\n",
    "# print(len(fiducial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate classification metrics on the subsamples\n",
    "\n",
    "do it along the way to making the subsamples, especially important for non-extreme subsamples filling the space of classification metric values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to normalize ratios of classes to know how many are in the potential population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ddf_pos = n_ddf[sel_class]\n",
    "n_ddf_glob = sum([n_ddf[classid] for classid in maybe_sn_classes])\n",
    "n_ddf_neg = n_ddf_glob - n_ddf_pos\n",
    "\n",
    "n_class_glob = n_class_pos * n_ddf_glob / n_ddf_pos\n",
    "n_class_neg = {classid: math.ceil(n_class_glob * n_ddf[classid] / n_ddf_glob) for classid in maybe_sn_classes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now try to get rates for the samples using proclam functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deterministic_metrics(truth, classified_pos, type_key=sel_class):\n",
    "    true_rates = truth.groupby('code').count()['id']\n",
    "    tp_plus_fp = pd.merge(classified_pos, truth, right_index=True, #on='id',\n",
    "                left_on='id', right_on='object_id')[['id', 'code']]\n",
    "    \n",
    "    cm_to_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next, perturb randomly using vaguely `proclam` approach\n",
    "\n",
    "idea: mixture model of confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe consider `proclam` classifier archetypes for inspiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 'Uncertain'\n",
    "# cm = np.ones((M_classes, M_classes))\n",
    "\n",
    "# # 'Perfect'\n",
    "# cm = np.eye(M_classes) + 1.e-8\n",
    "\n",
    "# # 'Almost'\n",
    "# cm = np.eye(M_classes) + 0.1 * np.ones((M_classes, M_classes))\n",
    "\n",
    "# # 'Noisy'\n",
    "# cm = np.eye(M_classes) + 0.5 * np.ones((M_classes, M_classes))\n",
    "\n",
    "# # 'Tunnel Vision'\n",
    "# cm = np.ones((M_classes, M_classes))\n",
    "# cm = cm * np.asarray(0.1)[np.newaxis, np.newaxis]\n",
    "# cm[:, chosen] = cm[:, chosen] / M_classes\n",
    "# cm[chosen][chosen] += M_classes\n",
    "\n",
    "# # 'Cruise Control'\n",
    "# cm = np.eye(M_classes) + 1.e-8\n",
    "# cm[:] = cm[chosen]\n",
    "\n",
    "# # 'Subsuming'\n",
    "# cm = np.eye(M_classes) + 0.1 * np.ones((M_classes, M_classes))\n",
    "# cm[chosen] = cm[chosen-1]\n",
    "\n",
    "# # 'Mutually Subsuming'\n",
    "# cm = np.eye(M_classes) + 0.1 * np.ones((M_classes, M_classes))\n",
    "# cm[chosen][chosen+1] = cm[chosen][chosen]\n",
    "# cm[chosen+1][chosen] = cm[chosen+1][chosen+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_subsamp(cm, cm_indices, samp_key, epsilon):\n",
    "    cm_row = cm.T[cm_indices[samp_key]]\n",
    "    for typeid in cm_indices.keys():\n",
    "        if typeid != samp_key:\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next, make samples corresponding to metric values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start with purity and efficiency for binary classification situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tot_in_test = np.sum(cm, axis=1)\n",
    "# print(tot_in_test)\n",
    "\n",
    "# tp_in_test = np.diag(cm)\n",
    "# tpr_in_test = tp_in_test / tot_in_test\n",
    "# # print((tp_in_test, tpr_in_test))\n",
    "# efficiency = tpr_in_test\n",
    "# print(efficiency)\n",
    "\n",
    "# contamination_raw = np.sum(cm, axis=0) - tp_in_test\n",
    "# contamination_rate = contamination_raw / tot_in_test\n",
    "# # print((contamination_raw, contamination_rate))\n",
    "# purity = tp_in_test / (tp_in_test + contamination_raw)\n",
    "# print(purity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recidivator (Python 3)",
   "language": "python",
   "name": "recidivator_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
