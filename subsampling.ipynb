{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulating realistically bad-for-cosmology SN Ia samples from PLAsTiCC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "# import proclam\n",
    "\n",
    "rando = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/media/RESSPECT/data/PLAsTiCC/PLAsTiCC_zenodo/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classes we care about\n",
    "\n",
    "| `true_target`=`type` | `code` |\n",
    "| -------------------- | ------ |\n",
    "| 90 | SNIa |\n",
    "| 67 | SNIa-91bg |\n",
    "| 52 | SNIax |\n",
    "| 42 | SNII |\n",
    "| 62 | SNIbc |\n",
    "| 95 | SLSN-I |\n",
    "| 88 | AGN |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe_sn_classes = {90: 'SNIa', \n",
    "                    67: 'SNIa-91bg', \n",
    "                    52: 'SNIax', \n",
    "                    42: 'SNII', \n",
    "                    62: 'SNIbc', \n",
    "                    95: 'SLSN-I', \n",
    "                    88: 'AGN'}\n",
    "maybe_sn_classes[64] = 'KN'\n",
    "maybe_sn_classes[15] = 'TDE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gather all DDF lightcurves\n",
    "\n",
    "only do it once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(datapath+'plasticc_train_metadata.csv', 'rb') as filename:\n",
    "#     train = pd.read_csv(filename)\n",
    "    \n",
    "# train_in_ddf = train[train['ddf_bool']==1]\n",
    "# # print(str(len(train_in_ddf))+' in DDF of '+str(len(train))+' total training set') \n",
    "# print(train_in_ddf.groupby('true_target').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with gzip.open(datapath+'plasticc_test_metadata.csv.gz', 'rb') as filename:\n",
    "#     test = pd.read_csv(filename)\n",
    "\n",
    "# test_in_ddf = test[test['ddf_bool']==1]\n",
    "# # print(str(len(test_in_ddf))+' in DDF of '+str(len(test))+' total test set') \n",
    "# print(test_in_ddf.groupby('true_target').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "put them together and save critical info for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe_sn_train = train_in_ddf.loc[train_in_ddf['true_target'].isin(maybe_sn_classes.keys())]\n",
    "# maybe_sn_test = test_in_ddf.loc[test_in_ddf['true_target'].isin(maybe_sn_classes.keys())]\n",
    "# all_maybe_sn = pd.concat((maybe_sn_train, maybe_sn_test))[['object_id', 'hostgal_specz', 'true_target']].set_index('object_id')\n",
    "# all_maybe_sn.to_csv('ddf_only.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subsample the classes to make new samples\n",
    "\n",
    "go +/- 25% from fiducial contamination rates from a (forthcoming) confusion matrix at `/media/RESSPECT/data/PLAsTiCC/for_metrics/confusion_matrices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_maybe_sn = pd.read_csv('ddf_only.csv')#, index_col='object_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_maybe_sn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savecounts = all_maybe_sn.groupby('true_target').count()['object_id'].to_numpy()\n",
    "print(savecounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/RESSPECT/data/PLAsTiCC/for_metrics/confusion_matrices/confusion_matrix.npy', 'rb') as confmat:\n",
    "    cm = np.load(confmat)\n",
    "    \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are just test set lightcurves for classes (67, 88, 42(minus 7?), 90(minus 11?), 52, 62, 64, 95, 15)\n",
    "                    \n",
    "So take out -1 and -3 row/col to match the classes being considered here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_classes = [67, 88, 42, 90, 52, 62, 64, 95, 15]\n",
    "cm_indices = {}\n",
    "for classid in maybe_sn_classes.keys():\n",
    "    cm_indices[classid] = cm_classes.index(classid)\n",
    "cm_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get sample ids for a given row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_samp_ids(cm, cm_indices, samp_key, savepath=None, rando=rando):\n",
    "    cm_row = cm.T[cm_indices[samp_key]]\n",
    "#     print((cm_row, np.sum(cm_row)))\n",
    "    out_ids = []\n",
    "    for typeid in cm_indices.keys():\n",
    "        n_to_sample = cm_row[cm_indices[typeid]]\n",
    "        print(n_to_sample)\n",
    "        matches = all_maybe_sn['object_id'][all_maybe_sn['true_target'] == typeid].sample(n=n_to_sample)#, random_state=rando)\n",
    "        out_ids += matches.to_list()\n",
    "    if savepath:\n",
    "        with open(savepath+'.pkl', 'wb') as tosave:\n",
    "            pkl.dump(out_ids, tosave)\n",
    "    return(out_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(n_to_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiducial = gen_samp_ids(cm, cm_indices, 90, savepath='/media/RESSPECT/data/PLAsTiCC/for_metrics/fiducial_ids')\n",
    "# print(len(fiducial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_perfect = np.diag(cm) * np.identity(len(cm_indices.keys()))\n",
    "perfect = gen_samp_ids(cm_perfect, cm_indices, 90, savepath='/media/RESSPECT/data/PLAsTiCC/for_metrics/perfect_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_subsamp(cm, cm_indices, samp_key, epsilon):\n",
    "    cm_row = cm.T[cm_indices[samp_key]]\n",
    "    for typeid in cm_indices.keys():\n",
    "        if typeid != samp_key:\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start with purity and efficiency for binary classification situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_in_test = np.sum(cm, axis=1)\n",
    "print(tot_in_test)\n",
    "\n",
    "tp_in_test = np.diag(cm)\n",
    "tpr_in_test = tp_in_test / tot_in_test\n",
    "# print((tp_in_test, tpr_in_test))\n",
    "efficiency = tpr_in_test\n",
    "print(efficiency)\n",
    "\n",
    "contamination_raw = np.sum(cm, axis=0) - tp_in_test\n",
    "contamination_rate = contamination_raw / tot_in_test\n",
    "# print((contamination_raw, contamination_rate))\n",
    "purity = tp_in_test / (tp_in_test + contamination_raw)\n",
    "print(purity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save outputs\n",
    "\n",
    "as `id,redshift,type,code,orig_sample=test,queryable=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recidivator (Python 3)",
   "language": "python",
   "name": "recidivator_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
